<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Ollama</name>
    </assembly>
    <members>
        <member name="T:Ollama.Chat">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.Chat.History">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.Chat.Tools">
            <inheritdoc cref="P:Ollama.GenerateChatCompletionRequest.Tools"/>
        </member>
        <member name="P:Ollama.Chat.Calls">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.Chat.Client">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.Chat.Model">
            <inheritdoc cref="P:Ollama.GenerateChatCompletionRequest.Model"/>
        </member>
        <member name="P:Ollama.Chat.AutoCallTools">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.Chat.ResponseFormat">
            <inheritdoc cref="P:Ollama.GenerateChatCompletionRequest.Format"/>
        </member>
        <member name="P:Ollama.Chat.RequestOptions">
            <inheritdoc cref="P:Ollama.GenerateChatCompletionRequest.Options"/>
        </member>
        <member name="P:Ollama.Chat.KeepAlive">
            <inheritdoc cref="P:Ollama.GenerateChatCompletionRequest.KeepAlive"/>
        </member>
        <member name="M:Ollama.Chat.#ctor(Ollama.OllamaApiClient,System.String,System.String,System.Nullable{Ollama.ResponseFormat},Ollama.RequestOptions,System.Nullable{System.Int32})">
            <summary>
            
            </summary>
            <param name="client"></param>
            <param name="model"></param>
            <param name="systemMessage"></param>
            <param name="format">
            The format to return a response in. Currently the only accepted value is json.<br/>
            Enable JSON mode by setting the format parameter to json. This will structure the response as valid JSON.<br/>
            Note: it's important to instruct the model to use JSON in the prompt. Otherwise, the model may generate large amounts whitespace.
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <exception cref="T:System.ArgumentNullException"></exception>
        </member>
        <member name="M:Ollama.Chat.AddToolService(System.Collections.Generic.IList{Ollama.Tool},System.Collections.Generic.IReadOnlyDictionary{System.String,System.Func{System.String,System.Threading.CancellationToken,System.Threading.Tasks.Task{System.String}}})">
            <summary>
            
            </summary>
            <param name="tools"></param>
            <param name="calls"></param>
        </member>
        <member name="M:Ollama.Chat.SendAsync(System.String,Ollama.MessageRole,System.Collections.Generic.IEnumerable{System.String},System.Threading.CancellationToken)">
            <summary>
            Sends a message in a given role(User by default) to the currently selected model
            </summary>
            <param name="role">The role in which the message should be sent</param>
            <param name="message">The message to send</param>
            <param name="imagesAsBase64">Base64 encoded images to send to the model</param>
            <param name="cancellationToken">The token to cancel the operation with</param>
        </member>
        <member name="M:Ollama.Chat.PrintMessages">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.Chat.PrintMessages(System.Collections.Generic.List{Ollama.Message})">
            <summary>
            
            </summary>
            <param name="messages"></param>
        </member>
        <member name="T:Ollama.StringExtensions">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.StringExtensions.AsUserMessage(System.String)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.StringExtensions.AsAssistantMessage(System.String)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.StringExtensions.AsSystemMessage(System.String)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.StringExtensions.AsToolMessage(System.String)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.StringExtensions.AsJson(System.Object)">
            <summary>
            
            </summary>
            <param name="args"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.StringExtensions.AsOllamaTools(System.Collections.Generic.IList{CSharpToJsonSchema.Tool})">
            <summary>
            
            </summary>
            <param name="tools"></param>
            <returns></returns>
        </member>
        <member name="T:Ollama.AnyOf`2">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.AnyOf`2.Value1">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.AnyOf`2.IsValue1">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.op_Implicit(`0)~Ollama.AnyOf{`0,`1}">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.op_Implicit(Ollama.AnyOf{`0,`1})~`0">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.#ctor(`0)">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.AnyOf`2.Value2">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.AnyOf`2.IsValue2">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.op_Implicit(`1)~Ollama.AnyOf{`0,`1}">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.op_Implicit(Ollama.AnyOf{`0,`1})~`1">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.#ctor(`1)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.#ctor(`0,`1)">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.AnyOf`2.Object">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.Validate">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.Match``1(System.Func{`0,``0},System.Func{`1,``0},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.Match(System.Action{`0},System.Action{`1},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.GetHashCode">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.Equals(Ollama.AnyOf{`0,`1})">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.op_Equality(Ollama.AnyOf{`0,`1},Ollama.AnyOf{`0,`1})">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.op_Inequality(Ollama.AnyOf{`0,`1},Ollama.AnyOf{`0,`1})">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.Equals(System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.AnyOf`2.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.JsonConverters.AnyOfJsonConverter`2">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.AnyOfJsonConverter`2.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.AnyOfJsonConverter`2.Write(System.Text.Json.Utf8JsonWriter,Ollama.AnyOf{`0,`1},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.CreateModelStatusJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.CreateModelStatusJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.CreateModelStatusJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.CreateModelStatus,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.CreateModelStatusEnumJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.CreateModelStatusEnumJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.CreateModelStatusEnumJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.CreateModelStatusEnum,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.CreateModelStatusEnumNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.CreateModelStatusEnumNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.CreateModelStatusEnumNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.CreateModelStatusEnum},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.DoneReasonJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.DoneReasonJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.DoneReasonJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.DoneReason,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.DoneReasonEnumJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.DoneReasonEnumJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.DoneReasonEnumJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.DoneReasonEnum,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.DoneReasonEnumNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.DoneReasonEnumNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.DoneReasonEnumNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.DoneReasonEnum},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.MessageRoleJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.MessageRoleJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.MessageRoleJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.MessageRole,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.MessageRoleNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.MessageRoleNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.MessageRoleNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.MessageRole},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.PullModelStatusJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PullModelStatusJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PullModelStatusJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.PullModelStatus,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.PullModelStatusEnumJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PullModelStatusEnumJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PullModelStatusEnumJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.PullModelStatusEnum,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.PullModelStatusEnumNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PullModelStatusEnumNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PullModelStatusEnumNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.PullModelStatusEnum},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.PushModelResponseStatusJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PushModelResponseStatusJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PushModelResponseStatusJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.PushModelResponseStatus,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.PushModelResponseStatusNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PushModelResponseStatusNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.PushModelResponseStatusNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.PushModelResponseStatus},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.ResponseFormatJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ResponseFormatJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ResponseFormatJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.ResponseFormat,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.ResponseFormatEnumJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ResponseFormatEnumJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ResponseFormatEnumJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.ResponseFormatEnum,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.ResponseFormatEnumNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ResponseFormatEnumNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ResponseFormatEnumNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.ResponseFormatEnum},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.ToolTypeJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ToolTypeJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ToolTypeJsonConverter.Write(System.Text.Json.Utf8JsonWriter,Ollama.ToolType,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.ToolTypeNullableJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ToolTypeNullableJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.ToolTypeNullableJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.Nullable{Ollama.ToolType},System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.JsonConverters.UnixTimestampJsonConverter">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.UnixTimestampJsonConverter.Read(System.Text.Json.Utf8JsonReader@,System.Type,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="M:Ollama.JsonConverters.UnixTimestampJsonConverter.Write(System.Text.Json.Utf8JsonWriter,System.DateTimeOffset,System.Text.Json.JsonSerializerOptions)">
            <inheritdoc />
        </member>
        <member name="T:Ollama.SourceGenerationContext">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Boolean">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableBoolean">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ByteArray">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Double">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableDouble">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Single">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableSingle">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.OpenApiSchema">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.AnyOfStringNullablePushModelResponseStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableAnyOfStringNullablePushModelResponseStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.CopyModelRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.CreateModelRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.CreateModelResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.CreateModelStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableCreateModelStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.CreateModelStatusEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableCreateModelStatusEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.DeleteModelRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.DoneReason">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableDoneReason">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.DoneReasonEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableDoneReasonEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GenerateChatCompletionRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GenerateChatCompletionResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GenerateCompletionRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GenerateCompletionResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GenerateEmbeddingRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GenerateEmbeddingResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.JsonSerializerContextTypes">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Message">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.MessageRole">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableMessageRole">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Model">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ModelDetails">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ModelInfo">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ModelInfoRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ModelInformation">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ModelsResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ProcessModel">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ProcessResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PullModelRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PullModelResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PullModelStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullablePullModelStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PullModelStatusEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullablePullModelStatusEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PushModelRequest">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PushModelResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.PushModelResponseStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullablePushModelResponseStatus">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.RequestOptions">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ResponseFormat">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableResponseFormat">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ResponseFormatEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableResponseFormatEnum">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Tool">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ToolCall">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ToolCallFunction">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ToolFunction">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.ToolType">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableToolType">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.VersionResponse">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.DictionaryStringObject">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.DictionaryStringString">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IDictionaryStringObject">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListDouble">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListMessage">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListModel">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListProcessModel">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListTool">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListToolCall">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListInt64">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IListString">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IReadOnlyDictionaryStringOpenApiSchema">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.IReadOnlyListString">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.DateTime">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableDateTime">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.JsonElement">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableJsonElement">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Int32">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableInt32">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Int64">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.NullableInt64">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Object">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.String">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.Default">
            <summary>
            The default <see cref="T:System.Text.Json.Serialization.JsonSerializerContext"/> associated with a default <see cref="T:System.Text.Json.JsonSerializerOptions"/> instance.
            </summary>
        </member>
        <member name="P:Ollama.SourceGenerationContext.GeneratedSerializerOptions">
            <summary>
            The source-generated options associated with this context.
            </summary>
        </member>
        <member name="M:Ollama.SourceGenerationContext.#ctor">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.SourceGenerationContext.#ctor(System.Text.Json.JsonSerializerOptions)">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.SourceGenerationContext.GetTypeInfo(System.Type)">
            <inheritdoc/>
        </member>
        <member name="T:Ollama.JsonSerializerContextTypes">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.StringStringDictionary">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.StringObjectDictionary">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.JsonElement">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type0">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type1">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type2">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type3">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type4">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type5">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type6">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type7">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type8">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type9">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type10">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type11">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type12">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type13">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type14">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type15">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type16">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type17">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type18">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type19">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type20">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type21">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type22">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type23">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type24">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type25">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type26">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type27">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type28">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type29">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type30">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type31">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type32">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type33">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type34">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type35">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type36">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type37">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type38">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type39">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type40">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type41">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type42">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type43">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type44">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type45">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type46">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type47">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type48">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type49">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type50">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type51">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type52">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type53">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type54">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type55">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type56">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.Type57">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.JsonSerializerContextTypes.OpenApiSchema">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.ChatClient">
            <summary>
            Given a list of messages comprising a conversation, the model will return a response.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="F:Ollama.ChatClient.DefaultBaseUrl">
            <summary>
            Ollama server URL
            </summary>
        </member>
        <member name="P:Ollama.ChatClient.HttpClient">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ChatClient.BaseUri">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ChatClient.Authorizations">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ChatClient.ReadResponseAsString">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ChatClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ChatClient.#ctor(System.Net.Http.HttpClient,System.Uri,System.Collections.Generic.List{Ollama.EndPointAuthorization},System.Boolean)">
            <summary>
            Creates a new instance of the ChatClient.
            If no httpClient is provided, a new one will be created.
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
            <param name="httpClient">The HttpClient instance. If not provided, a new one will be created.</param>
            <param name="baseUri">The base URL for the API. If not provided, the default baseUri from OpenAPI spec will be used.</param>
            <param name="authorizations">The authorizations to use for the requests.</param>
            <param name="disposeHttpClient">Dispose the HttpClient when the instance is disposed. True by default.</param>
        </member>
        <member name="M:Ollama.ChatClient.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.ChatClient.GenerateChatCompletionAsync(Ollama.GenerateChatCompletionRequest,System.Threading.CancellationToken)">
            <summary>
            Generate the next message in a chat with a provided model.<br/>
            This is a streaming endpoint, so there will be a series of responses. The final response object will include statistics and additional data from the request.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ChatClient.GenerateChatCompletionAsync(System.String,System.Collections.Generic.IList{Ollama.Message},System.Nullable{Ollama.ResponseFormat},Ollama.RequestOptions,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Collections.Generic.IList{Ollama.Tool},System.Threading.CancellationToken)">
            <summary>
            Generate the next message in a chat with a provided model.<br/>
            This is a streaming endpoint, so there will be a series of responses. The final response object will include statistics and additional data from the request.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="messages">
            The messages of the chat, this can be used to keep a chat memory
            </param>
            <param name="format"></param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="tools">
            A list of tools the model may call.
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.CompletionsClient">
            <summary>
            Given a prompt, the model will generate a completion.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="F:Ollama.CompletionsClient.DefaultBaseUrl">
            <summary>
            Ollama server URL
            </summary>
        </member>
        <member name="P:Ollama.CompletionsClient.HttpClient">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.CompletionsClient.BaseUri">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.CompletionsClient.Authorizations">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.CompletionsClient.ReadResponseAsString">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.CompletionsClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CompletionsClient.#ctor(System.Net.Http.HttpClient,System.Uri,System.Collections.Generic.List{Ollama.EndPointAuthorization},System.Boolean)">
            <summary>
            Creates a new instance of the CompletionsClient.
            If no httpClient is provided, a new one will be created.
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
            <param name="httpClient">The HttpClient instance. If not provided, a new one will be created.</param>
            <param name="baseUri">The base URL for the API. If not provided, the default baseUri from OpenAPI spec will be used.</param>
            <param name="authorizations">The authorizations to use for the requests.</param>
            <param name="disposeHttpClient">Dispose the HttpClient when the instance is disposed. True by default.</param>
        </member>
        <member name="M:Ollama.CompletionsClient.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.CompletionsClient.GenerateCompletionAsync(Ollama.GenerateCompletionRequest,System.Threading.CancellationToken)">
            <summary>
            Generate a response for a given prompt with a provided model.<br/>
            The final response object will include statistics and additional data from the request.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.CompletionsClient.GenerateCompletionAsync(System.String,System.String,System.String,System.Collections.Generic.IList{System.String},System.String,System.String,System.Collections.Generic.IList{System.Int64},Ollama.RequestOptions,System.Nullable{Ollama.ResponseFormat},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary>
            Generate a response for a given prompt with a provided model.<br/>
            The final response object will include statistics and additional data from the request.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="prompt">
            The prompt to generate a response.<br/>
            Example: Why is the sky blue?
            </param>
            <param name="suffix">
            The text that comes after the inserted text.
            </param>
            <param name="images">
            (optional) a list of Base64-encoded images to include in the message (for multimodal models such as llava)
            </param>
            <param name="system">
            The system prompt to (overrides what is defined in the Modelfile).
            </param>
            <param name="template">
            The full prompt or prompt template (overrides what is defined in the Modelfile).
            </param>
            <param name="context">
            The context parameter returned from a previous request to [generateCompletion], this can be used to keep a short conversational memory.
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="format"></param>
            <param name="raw">
            If `true` no formatting will be applied to the prompt and no context will be returned. <br/>
            You may choose to use the `raw` parameter if you are specifying a full templated prompt in your request to the API, and are managing history yourself.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.EmbeddingsClient">
            <summary>
            Get a vector representation of a given input.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="F:Ollama.EmbeddingsClient.DefaultBaseUrl">
            <summary>
            Ollama server URL
            </summary>
        </member>
        <member name="P:Ollama.EmbeddingsClient.HttpClient">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.EmbeddingsClient.BaseUri">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.EmbeddingsClient.Authorizations">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.EmbeddingsClient.ReadResponseAsString">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.EmbeddingsClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.EmbeddingsClient.#ctor(System.Net.Http.HttpClient,System.Uri,System.Collections.Generic.List{Ollama.EndPointAuthorization},System.Boolean)">
            <summary>
            Creates a new instance of the EmbeddingsClient.
            If no httpClient is provided, a new one will be created.
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
            <param name="httpClient">The HttpClient instance. If not provided, a new one will be created.</param>
            <param name="baseUri">The base URL for the API. If not provided, the default baseUri from OpenAPI spec will be used.</param>
            <param name="authorizations">The authorizations to use for the requests.</param>
            <param name="disposeHttpClient">Dispose the HttpClient when the instance is disposed. True by default.</param>
        </member>
        <member name="M:Ollama.EmbeddingsClient.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.EmbeddingsClient.GenerateEmbeddingAsync(Ollama.GenerateEmbeddingRequest,System.Threading.CancellationToken)">
            <summary>
            Generate embeddings from a model.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.EmbeddingsClient.GenerateEmbeddingAsync(System.String,System.String,Ollama.RequestOptions,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary>
            Generate embeddings from a model.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="prompt">
            Text to generate embeddings for.<br/>
            Example: Here is an article about llamas...
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.ApiException">
            <summary>
            Represents an exception thrown by the API.
            </summary>
        </member>
        <member name="P:Ollama.ApiException.StatusCode">
            <summary>
            The HTTP status code of the response.
            </summary>
        </member>
        <member name="P:Ollama.ApiException.ResponseBody">
            <summary>
            The response body.
            </summary>
        </member>
        <member name="P:Ollama.ApiException.ResponseHeaders">
            <summary>
            The response headers.
            </summary>
        </member>
        <member name="M:Ollama.ApiException.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ApiException"/> class.
            </summary>
        </member>
        <member name="M:Ollama.ApiException.#ctor(System.String,System.Net.HttpStatusCode)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ApiException"/> class with a specified error message.
            </summary>
            <param name="message">The message that describes the error.</param>
            <param name="statusCode">The HTTP status code of the response.</param>
        </member>
        <member name="M:Ollama.ApiException.#ctor(System.String,System.Exception,System.Net.HttpStatusCode)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ApiException"/> class with a specified error message and a reference to the inner exception that is the cause of this exception.
            </summary>
            <param name="message">The error message that explains the reason for the exception.</param>
            <param name="innerException">The exception that is the cause of the current exception, or a null reference if no inner exception is specified.</param>
            <param name="statusCode">The HTTP status code of the response.</param>
        </member>
        <member name="T:Ollama.ApiException`1">
            <summary>
            Represents an exception thrown by the API.
            </summary>
            <typeparam name="T"></typeparam>
        </member>
        <member name="P:Ollama.ApiException`1.ResponseObject">
            <summary>
            The response object.
            </summary>
        </member>
        <member name="M:Ollama.ApiException`1.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ApiException"/> class.
            </summary>
        </member>
        <member name="M:Ollama.ApiException`1.#ctor(System.String,System.Net.HttpStatusCode)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ApiException"/> class with a specified error message.
            </summary>
            <param name="message">The message that describes the error.</param>
            <param name="statusCode">The HTTP status code of the response.</param>
        </member>
        <member name="M:Ollama.ApiException`1.#ctor(System.String,System.Exception,System.Net.HttpStatusCode)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ApiException"/> class with a specified error message and a reference to the inner exception that is the cause of this exception.
            </summary>
            <param name="message">The error message that explains the reason for the exception.</param>
            <param name="innerException">The exception that is the cause of the current exception, or a null reference if no inner exception is specified.</param>
            <param name="statusCode">The HTTP status code of the response.</param>
        </member>
        <member name="T:Ollama.IChatClient">
            <summary>
            Given a list of messages comprising a conversation, the model will return a response.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="P:Ollama.IChatClient.HttpClient">
            <summary>
            The HttpClient instance.
            </summary>
        </member>
        <member name="P:Ollama.IChatClient.BaseUri">
            <summary>
            The base URL for the API.
            </summary>
        </member>
        <member name="P:Ollama.IChatClient.Authorizations">
            <summary>
            The authorizations to use for the requests.
            </summary>
        </member>
        <member name="P:Ollama.IChatClient.ReadResponseAsString">
            <summary>
            Gets or sets a value indicating whether the response content should be read as a string.
            True by default in debug builds, false otherwise.
            </summary>
        </member>
        <member name="P:Ollama.IChatClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.IChatClient.GenerateChatCompletionAsync(Ollama.GenerateChatCompletionRequest,System.Threading.CancellationToken)">
            <summary>
            Generate the next message in a chat with a provided model.<br/>
            This is a streaming endpoint, so there will be a series of responses. The final response object will include statistics and additional data from the request.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IChatClient.GenerateChatCompletionAsync(System.String,System.Collections.Generic.IList{Ollama.Message},System.Nullable{Ollama.ResponseFormat},Ollama.RequestOptions,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Collections.Generic.IList{Ollama.Tool},System.Threading.CancellationToken)">
            <summary>
            Generate the next message in a chat with a provided model.<br/>
            This is a streaming endpoint, so there will be a series of responses. The final response object will include statistics and additional data from the request.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="messages">
            The messages of the chat, this can be used to keep a chat memory
            </param>
            <param name="format"></param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="tools">
            A list of tools the model may call.
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.ICompletionsClient">
            <summary>
            Given a prompt, the model will generate a completion.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="P:Ollama.ICompletionsClient.HttpClient">
            <summary>
            The HttpClient instance.
            </summary>
        </member>
        <member name="P:Ollama.ICompletionsClient.BaseUri">
            <summary>
            The base URL for the API.
            </summary>
        </member>
        <member name="P:Ollama.ICompletionsClient.Authorizations">
            <summary>
            The authorizations to use for the requests.
            </summary>
        </member>
        <member name="P:Ollama.ICompletionsClient.ReadResponseAsString">
            <summary>
            Gets or sets a value indicating whether the response content should be read as a string.
            True by default in debug builds, false otherwise.
            </summary>
        </member>
        <member name="P:Ollama.ICompletionsClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ICompletionsClient.GenerateCompletionAsync(Ollama.GenerateCompletionRequest,System.Threading.CancellationToken)">
            <summary>
            Generate a response for a given prompt with a provided model.<br/>
            The final response object will include statistics and additional data from the request.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ICompletionsClient.GenerateCompletionAsync(System.String,System.String,System.String,System.Collections.Generic.IList{System.String},System.String,System.String,System.Collections.Generic.IList{System.Int64},Ollama.RequestOptions,System.Nullable{Ollama.ResponseFormat},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary>
            Generate a response for a given prompt with a provided model.<br/>
            The final response object will include statistics and additional data from the request.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="prompt">
            The prompt to generate a response.<br/>
            Example: Why is the sky blue?
            </param>
            <param name="suffix">
            The text that comes after the inserted text.
            </param>
            <param name="images">
            (optional) a list of Base64-encoded images to include in the message (for multimodal models such as llava)
            </param>
            <param name="system">
            The system prompt to (overrides what is defined in the Modelfile).
            </param>
            <param name="template">
            The full prompt or prompt template (overrides what is defined in the Modelfile).
            </param>
            <param name="context">
            The context parameter returned from a previous request to [generateCompletion], this can be used to keep a short conversational memory.
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="format"></param>
            <param name="raw">
            If `true` no formatting will be applied to the prompt and no context will be returned. <br/>
            You may choose to use the `raw` parameter if you are specifying a full templated prompt in your request to the API, and are managing history yourself.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.IEmbeddingsClient">
            <summary>
            Get a vector representation of a given input.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="P:Ollama.IEmbeddingsClient.HttpClient">
            <summary>
            The HttpClient instance.
            </summary>
        </member>
        <member name="P:Ollama.IEmbeddingsClient.BaseUri">
            <summary>
            The base URL for the API.
            </summary>
        </member>
        <member name="P:Ollama.IEmbeddingsClient.Authorizations">
            <summary>
            The authorizations to use for the requests.
            </summary>
        </member>
        <member name="P:Ollama.IEmbeddingsClient.ReadResponseAsString">
            <summary>
            Gets or sets a value indicating whether the response content should be read as a string.
            True by default in debug builds, false otherwise.
            </summary>
        </member>
        <member name="P:Ollama.IEmbeddingsClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.IEmbeddingsClient.GenerateEmbeddingAsync(Ollama.GenerateEmbeddingRequest,System.Threading.CancellationToken)">
            <summary>
            Generate embeddings from a model.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IEmbeddingsClient.GenerateEmbeddingAsync(System.String,System.String,Ollama.RequestOptions,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary>
            Generate embeddings from a model.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="prompt">
            Text to generate embeddings for.<br/>
            Example: Here is an article about llamas...
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.IModelsClient">
            <summary>
            List and describe the various models available.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="M:Ollama.IModelsClient.CheckBlobAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Ensures that the file blob used for a FROM or ADAPTER field exists on the server.<br/>
            This is checking your Ollama server and not Ollama.ai.
            </summary>
            <param name="digest"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.CopyModelAsync(Ollama.CopyModelRequest,System.Threading.CancellationToken)">
            <summary>
            Creates a model with another name from an existing model.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.CopyModelAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary>
            Creates a model with another name from an existing model.
            </summary>
            <param name="source">
            Name of the model to copy.<br/>
            Example: llama3.2
            </param>
            <param name="destination">
            Name of the new model.<br/>
            Example: llama3-backup
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.CreateBlobAsync(System.String,System.Byte[],System.Threading.CancellationToken)">
            <summary>
            Create a blob from a file. Returns the server file path.
            </summary>
            <param name="digest"></param>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.CreateBlobAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Create a blob from a file. Returns the server file path.
            </summary>
            <param name="digest"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.CreateModelAsync(Ollama.CreateModelRequest,System.Threading.CancellationToken)">
            <summary>
            Create a model from a Modelfile.<br/>
            It is recommended to set `modelfile` to the content of the Modelfile rather than just set `path`. This is a requirement for remote create. Remote model creation should also create any file blobs, fields such as `FROM` and `ADAPTER`, explicitly with the server using Create a Blob and the value to the path indicated in the response.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.CreateModelAsync(System.String,System.String,System.String,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            Create a model from a Modelfile.<br/>
            It is recommended to set `modelfile` to the content of the Modelfile rather than just set `path`. This is a requirement for remote create. Remote model creation should also create any file blobs, fields such as `FROM` and `ADAPTER`, explicitly with the server using Create a Blob and the value to the path indicated in the response.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: mario
            </param>
            <param name="modelfile">
            The contents of the Modelfile.<br/>
            Example: FROM llama3\nSYSTEM You are mario from Super Mario Bros.
            </param>
            <param name="path">
            Path to the Modelfile (optional)
            </param>
            <param name="quantize">
            The quantization level of the model.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.DeleteModelAsync(Ollama.DeleteModelRequest,System.Threading.CancellationToken)">
            <summary>
            Delete a model and its data.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.DeleteModelAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Delete a model and its data.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3:13b
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="P:Ollama.IModelsClient.HttpClient">
            <summary>
            The HttpClient instance.
            </summary>
        </member>
        <member name="P:Ollama.IModelsClient.BaseUri">
            <summary>
            The base URL for the API.
            </summary>
        </member>
        <member name="P:Ollama.IModelsClient.Authorizations">
            <summary>
            The authorizations to use for the requests.
            </summary>
        </member>
        <member name="P:Ollama.IModelsClient.ReadResponseAsString">
            <summary>
            Gets or sets a value indicating whether the response content should be read as a string.
            True by default in debug builds, false otherwise.
            </summary>
        </member>
        <member name="P:Ollama.IModelsClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.IModelsClient.ListModelsAsync(System.Threading.CancellationToken)">
            <summary>
            List models that are available locally.
            </summary>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.ListRunningModelsAsync(System.Threading.CancellationToken)">
            <summary>
            List models that are running.
            </summary>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.PullModelAsync(Ollama.PullModelRequest,System.Threading.CancellationToken)">
            <summary>
            Download a model from the ollama library.<br/>
            Cancelled pulls are resumed from where they left off, and multiple calls will share the same download progress.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.PullModelAsync(System.String,System.Nullable{System.Boolean},System.String,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            Download a model from the ollama library.<br/>
            Cancelled pulls are resumed from where they left off, and multiple calls will share the same download progress.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="insecure">
            Allow insecure connections to the library. <br/>
            Only use this if you are pulling from your own library during development.<br/>
            Default Value: false
            </param>
            <param name="username">
            Ollama username.
            </param>
            <param name="password">
            Ollama password.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.PushModelAsync(Ollama.PushModelRequest,System.Threading.CancellationToken)">
            <summary>
            Upload a model to a model library.<br/>
            Requires registering for ollama.ai and adding a public key first.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.PushModelAsync(System.String,System.Nullable{System.Boolean},System.String,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            Upload a model to a model library.<br/>
            Requires registering for ollama.ai and adding a public key first.
            </summary>
            <param name="model">
            The name of the model to push in the form of &lt;namespace&gt;/&lt;model&gt;:&lt;tag&gt;.<br/>
            Example: mattw/pygmalion:latest
            </param>
            <param name="insecure">
            Allow insecure connections to the library. <br/>
            Only use this if you are pushing to your library during development.<br/>
            Default Value: false
            </param>
            <param name="username">
            Ollama username.
            </param>
            <param name="password">
            Ollama password.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.ShowModelInfoAsync(Ollama.ModelInfoRequest,System.Threading.CancellationToken)">
            <summary>
            Show details about a model including modelfile, template, parameters, license, and system prompt.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.IModelsClient.ShowModelInfoAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Show details about a model including modelfile, template, parameters, license, and system prompt.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.IOllamaApiClient">
            <summary>
            API Spec for Ollama API. Please see https://github.com/jmorganca/ollama/blob/main/docs/api.md for more details.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.HttpClient">
            <summary>
            The HttpClient instance.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.BaseUri">
            <summary>
            The base URL for the API.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.Authorizations">
            <summary>
            The authorizations to use for the requests.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.ReadResponseAsString">
            <summary>
            Gets or sets a value indicating whether the response content should be read as a string.
            True by default in debug builds, false otherwise.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.Completions">
            <summary>
            Given a prompt, the model will generate a completion.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.Chat">
            <summary>
            Given a list of messages comprising a conversation, the model will return a response.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.Embeddings">
            <summary>
            Get a vector representation of a given input.
            </summary>
        </member>
        <member name="P:Ollama.IOllamaApiClient.Models">
            <summary>
            List and describe the various models available.
            </summary>
        </member>
        <member name="M:Ollama.IOllamaApiClient.GetVersionAsync(System.Threading.CancellationToken)">
            <summary>
            Returns the version of the Ollama server.<br/>
            This endpoint returns the version of the Ollama server.
            </summary>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="T:Ollama.CopyModelRequest">
            <summary>
            Request class for copying a model.
            </summary>
        </member>
        <member name="P:Ollama.CopyModelRequest.Source">
            <summary>
            Name of the model to copy.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.CopyModelRequest.Destination">
            <summary>
            Name of the new model.<br/>
            Example: llama3-backup
            </summary>
            <example>llama3-backup</example>
        </member>
        <member name="P:Ollama.CopyModelRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.#ctor(System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.CopyModelRequest" /> class.
            </summary>
            <param name="source">
            Name of the model to copy.<br/>
            Example: llama3.2
            </param>
            <param name="destination">
            Name of the new model.<br/>
            Example: llama3-backup
            </param>
        </member>
        <member name="M:Ollama.CopyModelRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.CopyModelRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CopyModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.CreateModelRequest">
            <summary>
            Create model request object.
            </summary>
        </member>
        <member name="P:Ollama.CreateModelRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: mario
            </summary>
            <example>mario</example>
        </member>
        <member name="P:Ollama.CreateModelRequest.Modelfile">
            <summary>
            The contents of the Modelfile.<br/>
            Example: FROM llama3\nSYSTEM You are mario from Super Mario Bros.
            </summary>
            <example>FROM llama3\nSYSTEM You are mario from Super Mario Bros.</example>
        </member>
        <member name="P:Ollama.CreateModelRequest.Path">
            <summary>
            Path to the Modelfile (optional)
            </summary>
        </member>
        <member name="P:Ollama.CreateModelRequest.Quantize">
            <summary>
            The quantization level of the model.
            </summary>
        </member>
        <member name="P:Ollama.CreateModelRequest.Stream">
            <summary>
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </summary>
        </member>
        <member name="P:Ollama.CreateModelRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.#ctor(System.String,System.String,System.String,System.String,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.CreateModelRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: mario
            </param>
            <param name="modelfile">
            The contents of the Modelfile.<br/>
            Example: FROM llama3\nSYSTEM You are mario from Super Mario Bros.
            </param>
            <param name="path">
            Path to the Modelfile (optional)
            </param>
            <param name="quantize">
            The quantization level of the model.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
        </member>
        <member name="M:Ollama.CreateModelRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.CreateModelRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.CreateModelResponse">
            <summary>
            Response object for creating a model. When finished, `status` is `success`.
            </summary>
        </member>
        <member name="P:Ollama.CreateModelResponse.Status">
            <summary>
            Status creating the model
            </summary>
        </member>
        <member name="P:Ollama.CreateModelResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.#ctor(System.Nullable{Ollama.CreateModelStatus})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.CreateModelResponse" /> class.
            </summary>
            <param name="status">
            Status creating the model
            </param>
        </member>
        <member name="M:Ollama.CreateModelResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.CreateModelResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.CreateModelStatus">
            <summary>
            Status creating the model
            </summary>
        </member>
        <member name="P:Ollama.CreateModelStatus.Value1">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.CreateModelStatus.IsValue1">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.op_Implicit(System.String)~Ollama.CreateModelStatus">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.op_Implicit(Ollama.CreateModelStatus)~System.String">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.#ctor(System.String)">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.CreateModelStatus.Value2">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.CreateModelStatus.IsValue2">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.op_Implicit(Ollama.CreateModelStatusEnum)~Ollama.CreateModelStatus">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.op_Implicit(Ollama.CreateModelStatus)~System.Nullable{Ollama.CreateModelStatusEnum}">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.#ctor(System.Nullable{Ollama.CreateModelStatusEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.#ctor(System.String,System.Nullable{Ollama.CreateModelStatusEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.CreateModelStatus.Object">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.Validate">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.Match``1(System.Func{System.String,``0},System.Func{System.Nullable{Ollama.CreateModelStatusEnum},``0},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.Match(System.Action{System.String},System.Action{System.Nullable{Ollama.CreateModelStatusEnum}},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.GetHashCode">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.Equals(Ollama.CreateModelStatus)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.op_Equality(Ollama.CreateModelStatus,Ollama.CreateModelStatus)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.op_Inequality(Ollama.CreateModelStatus,Ollama.CreateModelStatus)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.Equals(System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatus.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.CreateModelStatusEnum">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.CreateModelStatusEnum.CreatingSystemLayer">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.CreateModelStatusEnum.ParsingModelfile">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.CreateModelStatusEnum.Success">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.CreateModelStatusEnumExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatusEnumExtensions.ToValueString(Ollama.CreateModelStatusEnum)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.CreateModelStatusEnumExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.DeleteModelRequest">
            <summary>
            Request class for deleting a model.
            </summary>
        </member>
        <member name="P:Ollama.DeleteModelRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3:13b
            </summary>
            <example>llama3:13b</example>
        </member>
        <member name="P:Ollama.DeleteModelRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.DeleteModelRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3:13b
            </param>
        </member>
        <member name="M:Ollama.DeleteModelRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.DeleteModelRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.DeleteModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.DoneReason">
            <summary>
            Reason why the model is done generating a response.
            </summary>
        </member>
        <member name="P:Ollama.DoneReason.Value1">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.DoneReason.IsValue1">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.op_Implicit(System.String)~Ollama.DoneReason">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.op_Implicit(Ollama.DoneReason)~System.String">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.#ctor(System.String)">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.DoneReason.Value2">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.DoneReason.IsValue2">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.op_Implicit(Ollama.DoneReasonEnum)~Ollama.DoneReason">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.op_Implicit(Ollama.DoneReason)~System.Nullable{Ollama.DoneReasonEnum}">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.#ctor(System.Nullable{Ollama.DoneReasonEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.#ctor(System.String,System.Nullable{Ollama.DoneReasonEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.DoneReason.Object">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.Validate">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.Match``1(System.Func{System.String,``0},System.Func{System.Nullable{Ollama.DoneReasonEnum},``0},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.Match(System.Action{System.String},System.Action{System.Nullable{Ollama.DoneReasonEnum}},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.GetHashCode">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.Equals(Ollama.DoneReason)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.op_Equality(Ollama.DoneReason,Ollama.DoneReason)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.op_Inequality(Ollama.DoneReason,Ollama.DoneReason)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.Equals(System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.DoneReason.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.DoneReasonEnum">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.DoneReasonEnum.Stop">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.DoneReasonEnum.Length">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.DoneReasonEnum.Load">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.DoneReasonEnumExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.DoneReasonEnumExtensions.ToValueString(Ollama.DoneReasonEnum)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.DoneReasonEnumExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.GenerateChatCompletionRequest">
            <summary>
            Request class for the chat endpoint.
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.Messages">
            <summary>
            The messages of the chat, this can be used to keep a chat memory
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.Format">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.Options">
            <summary>
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.Stream">
            <summary>
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.KeepAlive">
            <summary>
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.Tools">
            <summary>
            A list of tools the model may call.
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.#ctor(System.String,System.Collections.Generic.IList{Ollama.Message},System.Nullable{Ollama.ResponseFormat},Ollama.RequestOptions,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Collections.Generic.IList{Ollama.Tool})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateChatCompletionRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="messages">
            The messages of the chat, this can be used to keep a chat memory
            </param>
            <param name="format"></param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
            <param name="tools">
            A list of tools the model may call.
            </param>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateChatCompletionRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.GenerateChatCompletionResponse">
            <summary>
            The response class for the chat endpoint.
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.Message">
            <summary>
            A message in the chat endpoint
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.CreatedAt">
            <summary>
            Date on which a model was created.
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.Done">
            <summary>
            Whether the response has completed.<br/>
            Example: true
            </summary>
            <example>true</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.DoneReason">
            <summary>
            Reason why the model is done generating a response.
            </summary>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.TotalDuration">
            <summary>
            Time spent generating the response.<br/>
            Example: 5589157167L
            </summary>
            <example>5589157167L</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.LoadDuration">
            <summary>
            Time spent in nanoseconds loading the model.<br/>
            Example: 3013701500L
            </summary>
            <example>3013701500L</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.PromptEvalCount">
            <summary>
            Number of tokens in the prompt.<br/>
            Example: 46
            </summary>
            <example>46</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.PromptEvalDuration">
            <summary>
            Time spent in nanoseconds evaluating the prompt.<br/>
            Example: 1160282000L
            </summary>
            <example>1160282000L</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.EvalCount">
            <summary>
            Number of tokens the response.<br/>
            Example: 113
            </summary>
            <example>113</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.EvalDuration">
            <summary>
            Time in nanoseconds spent generating the response.<br/>
            Example: 1325948000L
            </summary>
            <example>1325948000L</example>
        </member>
        <member name="P:Ollama.GenerateChatCompletionResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.#ctor(Ollama.Message,System.String,System.DateTime,System.Boolean,System.Nullable{Ollama.DoneReason},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int32},System.Nullable{System.Int64},System.Nullable{System.Int32},System.Nullable{System.Int64})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateChatCompletionResponse" /> class.
            </summary>
            <param name="message">
            A message in the chat endpoint
            </param>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="createdAt">
            Date on which a model was created.
            </param>
            <param name="done">
            Whether the response has completed.<br/>
            Example: true
            </param>
            <param name="doneReason">
            Reason why the model is done generating a response.
            </param>
            <param name="totalDuration">
            Time spent generating the response.<br/>
            Example: 5589157167L
            </param>
            <param name="loadDuration">
            Time spent in nanoseconds loading the model.<br/>
            Example: 3013701500L
            </param>
            <param name="promptEvalCount">
            Number of tokens in the prompt.<br/>
            Example: 46
            </param>
            <param name="promptEvalDuration">
            Time spent in nanoseconds evaluating the prompt.<br/>
            Example: 1160282000L
            </param>
            <param name="evalCount">
            Number of tokens the response.<br/>
            Example: 113
            </param>
            <param name="evalDuration">
            Time in nanoseconds spent generating the response.<br/>
            Example: 1325948000L
            </param>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateChatCompletionResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateChatCompletionResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.GenerateCompletionRequest">
            <summary>
            Request class for the generate endpoint.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Prompt">
            <summary>
            The prompt to generate a response.<br/>
            Example: Why is the sky blue?
            </summary>
            <example>Why is the sky blue?</example>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Suffix">
            <summary>
            The text that comes after the inserted text.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Images">
            <summary>
            (optional) a list of Base64-encoded images to include in the message (for multimodal models such as llava)
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.System">
            <summary>
            The system prompt to (overrides what is defined in the Modelfile).
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Template">
            <summary>
            The full prompt or prompt template (overrides what is defined in the Modelfile).
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Context">
            <summary>
            The context parameter returned from a previous request to [generateCompletion], this can be used to keep a short conversational memory.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Options">
            <summary>
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Format">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Raw">
            <summary>
            If `true` no formatting will be applied to the prompt and no context will be returned. <br/>
            You may choose to use the `raw` parameter if you are specifying a full templated prompt in your request to the API, and are managing history yourself.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.Stream">
            <summary>
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.KeepAlive">
            <summary>
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.#ctor(System.String,System.String,System.String,System.Collections.Generic.IList{System.String},System.String,System.String,System.Collections.Generic.IList{System.Int64},Ollama.RequestOptions,System.Nullable{Ollama.ResponseFormat},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateCompletionRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="prompt">
            The prompt to generate a response.<br/>
            Example: Why is the sky blue?
            </param>
            <param name="suffix">
            The text that comes after the inserted text.
            </param>
            <param name="images">
            (optional) a list of Base64-encoded images to include in the message (for multimodal models such as llava)
            </param>
            <param name="system">
            The system prompt to (overrides what is defined in the Modelfile).
            </param>
            <param name="template">
            The full prompt or prompt template (overrides what is defined in the Modelfile).
            </param>
            <param name="context">
            The context parameter returned from a previous request to [generateCompletion], this can be used to keep a short conversational memory.
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="format"></param>
            <param name="raw">
            If `true` no formatting will be applied to the prompt and no context will be returned. <br/>
            You may choose to use the `raw` parameter if you are specifying a full templated prompt in your request to the API, and are managing history yourself.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateCompletionRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.GenerateCompletionResponse">
            <summary>
            The response class for the generate endpoint.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.CreatedAt">
            <summary>
            Date on which a model was created.
            </summary>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.Response">
            <summary>
            The response for a given prompt with a provided model.<br/>
            Example: The sky appears blue because of a phenomenon called Rayleigh scattering.
            </summary>
            <example>The sky appears blue because of a phenomenon called Rayleigh scattering.</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.Done">
            <summary>
            Whether the response has completed.<br/>
            Example: true
            </summary>
            <example>true</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.Context">
            <summary>
            An encoding of the conversation used in this response, this can be sent in the next request to keep a conversational memory.<br/>
            Example: [1L, 2L, 3L]
            </summary>
            <example>[1L, 2L, 3L]</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.TotalDuration">
            <summary>
            Time spent generating the response.<br/>
            Example: 5589157167L
            </summary>
            <example>5589157167L</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.LoadDuration">
            <summary>
            Time spent in nanoseconds loading the model.<br/>
            Example: 3013701500L
            </summary>
            <example>3013701500L</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.PromptEvalCount">
            <summary>
            Number of tokens in the prompt.<br/>
            Example: 46
            </summary>
            <example>46</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.PromptEvalDuration">
            <summary>
            Time spent in nanoseconds evaluating the prompt.<br/>
            Example: 1160282000L
            </summary>
            <example>1160282000L</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.EvalCount">
            <summary>
            Number of tokens the response.<br/>
            Example: 113
            </summary>
            <example>113</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.EvalDuration">
            <summary>
            Time in nanoseconds spent generating the response.<br/>
            Example: 1325948000L
            </summary>
            <example>1325948000L</example>
        </member>
        <member name="P:Ollama.GenerateCompletionResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.#ctor(System.String,System.Nullable{System.DateTime},System.String,System.Nullable{System.Boolean},System.Collections.Generic.IList{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int32},System.Nullable{System.Int64},System.Nullable{System.Int32},System.Nullable{System.Int64})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateCompletionResponse" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="createdAt">
            Date on which a model was created.
            </param>
            <param name="response">
            The response for a given prompt with a provided model.<br/>
            Example: The sky appears blue because of a phenomenon called Rayleigh scattering.
            </param>
            <param name="done">
            Whether the response has completed.<br/>
            Example: true
            </param>
            <param name="context">
            An encoding of the conversation used in this response, this can be sent in the next request to keep a conversational memory.<br/>
            Example: [1L, 2L, 3L]
            </param>
            <param name="totalDuration">
            Time spent generating the response.<br/>
            Example: 5589157167L
            </param>
            <param name="loadDuration">
            Time spent in nanoseconds loading the model.<br/>
            Example: 3013701500L
            </param>
            <param name="promptEvalCount">
            Number of tokens in the prompt.<br/>
            Example: 46
            </param>
            <param name="promptEvalDuration">
            Time spent in nanoseconds evaluating the prompt.<br/>
            Example: 1160282000L
            </param>
            <param name="evalCount">
            Number of tokens the response.<br/>
            Example: 113
            </param>
            <param name="evalDuration">
            Time in nanoseconds spent generating the response.<br/>
            Example: 1325948000L
            </param>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateCompletionResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateCompletionResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.GenerateEmbeddingRequest">
            <summary>
            Generate embeddings from a model.
            </summary>
        </member>
        <member name="P:Ollama.GenerateEmbeddingRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.GenerateEmbeddingRequest.Prompt">
            <summary>
            Text to generate embeddings for.<br/>
            Example: Here is an article about llamas...
            </summary>
            <example>Here is an article about llamas...</example>
        </member>
        <member name="P:Ollama.GenerateEmbeddingRequest.Options">
            <summary>
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </summary>
        </member>
        <member name="P:Ollama.GenerateEmbeddingRequest.KeepAlive">
            <summary>
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </summary>
        </member>
        <member name="P:Ollama.GenerateEmbeddingRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.#ctor(System.String,System.String,Ollama.RequestOptions,System.Nullable{System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateEmbeddingRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="prompt">
            Text to generate embeddings for.<br/>
            Example: Here is an article about llamas...
            </param>
            <param name="options">
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </param>
            <param name="keepAlive">
            How long (in minutes) to keep the model loaded in memory.<br/>
            - If set to a positive duration (e.g. 20), the model will stay loaded for the provided duration.<br/>
            - If set to a negative duration (e.g. -1), the model will stay loaded indefinitely.<br/>
            - If set to 0, the model will be unloaded immediately once finished.<br/>
            - If not set, the model will stay loaded for 5 minutes by default
            </param>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateEmbeddingRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.GenerateEmbeddingResponse">
            <summary>
            Returns the embedding information.
            </summary>
        </member>
        <member name="P:Ollama.GenerateEmbeddingResponse.Embedding">
            <summary>
            The embedding for the prompt.<br/>
            Example: [0.5670403838157654, 0.009260174818336964, ...]
            </summary>
            <example>[0.5670403838157654, 0.009260174818336964, ...]</example>
        </member>
        <member name="P:Ollama.GenerateEmbeddingResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.#ctor(System.Collections.Generic.IList{System.Double})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateEmbeddingResponse" /> class.
            </summary>
            <param name="embedding">
            The embedding for the prompt.<br/>
            Example: [0.5670403838157654, 0.009260174818336964, ...]
            </param>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.GenerateEmbeddingResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.GenerateEmbeddingResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.Message">
            <summary>
            A message in the chat endpoint
            </summary>
        </member>
        <member name="P:Ollama.Message.Role">
            <summary>
            The role of the message
            </summary>
        </member>
        <member name="P:Ollama.Message.Content">
            <summary>
            The content of the message<br/>
            Example: Why is the sky blue?
            </summary>
            <example>Why is the sky blue?</example>
        </member>
        <member name="P:Ollama.Message.Images">
            <summary>
            (optional) a list of Base64-encoded images to include in the message (for multimodal models such as llava)
            </summary>
        </member>
        <member name="P:Ollama.Message.ToolCalls">
            <summary>
            A list of tools the model wants to call.
            </summary>
        </member>
        <member name="P:Ollama.Message.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.Message.#ctor(Ollama.MessageRole,System.String,System.Collections.Generic.IList{System.String},System.Collections.Generic.IList{Ollama.ToolCall})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.Message" /> class.
            </summary>
            <param name="role">
            The role of the message
            </param>
            <param name="content">
            The content of the message<br/>
            Example: Why is the sky blue?
            </param>
            <param name="images">
            (optional) a list of Base64-encoded images to include in the message (for multimodal models such as llava)
            </param>
            <param name="toolCalls">
            A list of tools the model wants to call.
            </param>
        </member>
        <member name="M:Ollama.Message.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.Message" /> class.
            </summary>
        </member>
        <member name="M:Ollama.Message.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Message.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Message.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Message.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Message.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Message.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Message.op_Implicit(System.String)~Ollama.Message">
            <summary>
            
            </summary>
            <param name="content"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.Message.ToMessage(System.String)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <returns></returns>
        </member>
        <member name="T:Ollama.MessageRole">
            <summary>
            The role of the message
            </summary>
        </member>
        <member name="F:Ollama.MessageRole.System">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.MessageRole.User">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.MessageRole.Assistant">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.MessageRole.Tool">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.MessageRoleExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.MessageRoleExtensions.ToValueString(Ollama.MessageRole)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.MessageRoleExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.Model">
            <summary>
            A model available locally.
            </summary>
        </member>
        <member name="P:Ollama.Model.Model1">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.Model.ModifiedAt">
            <summary>
            Model modification date.
            </summary>
        </member>
        <member name="P:Ollama.Model.Size">
            <summary>
            Size of the model on disk.<br/>
            Example: 7323310500L
            </summary>
            <example>7323310500L</example>
        </member>
        <member name="P:Ollama.Model.Digest">
            <summary>
            The model's digest.<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </summary>
            <example>sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a</example>
        </member>
        <member name="P:Ollama.Model.Details">
            <summary>
            Details about a model.
            </summary>
        </member>
        <member name="P:Ollama.Model.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.Model.#ctor(System.String,System.Nullable{System.DateTime},System.Nullable{System.Int64},System.String,Ollama.ModelDetails)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.Model" /> class.
            </summary>
            <param name="model1">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="modifiedAt">
            Model modification date.
            </param>
            <param name="size">
            Size of the model on disk.<br/>
            Example: 7323310500L
            </param>
            <param name="digest">
            The model's digest.<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </param>
            <param name="details">
            Details about a model.
            </param>
        </member>
        <member name="M:Ollama.Model.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.Model" /> class.
            </summary>
        </member>
        <member name="M:Ollama.Model.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Model.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Model.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Model.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Model.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Model.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ModelDetails">
            <summary>
            Details about a model.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.ParentModel">
            <summary>
            The parent model of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.Format">
            <summary>
            The format of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.Family">
            <summary>
            The family of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.Families">
            <summary>
            The families of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.ParameterSize">
            <summary>
            The size of the model's parameters.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.QuantizationLevel">
            <summary>
            The quantization level of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelDetails.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.#ctor(System.String,System.String,System.String,System.Collections.Generic.IList{System.String},System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelDetails" /> class.
            </summary>
            <param name="parentModel">
            The parent model of the model.
            </param>
            <param name="format">
            The format of the model.
            </param>
            <param name="family">
            The family of the model.
            </param>
            <param name="families">
            The families of the model.
            </param>
            <param name="parameterSize">
            The size of the model's parameters.
            </param>
            <param name="quantizationLevel">
            The quantization level of the model.
            </param>
        </member>
        <member name="M:Ollama.ModelDetails.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelDetails" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelDetails.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ModelInfo">
            <summary>
            Details about a model including modelfile, template, parameters, license, and system prompt.
            </summary>
        </member>
        <member name="P:Ollama.ModelInfo.License">
            <summary>
            The model's license.<br/>
            Example: &lt;contents of license block&gt;
            </summary>
            <example>&lt;contents of license block&gt;</example>
        </member>
        <member name="P:Ollama.ModelInfo.Modelfile">
            <summary>
            The modelfile associated with the model.<br/>
            Example: Modelfile generated by \"ollama show\"\n# To build a new Modelfile based on this one, replace the FROM line with:\n# FROM llama3:latest\n\nFROM /Users/username/.ollama/models/blobs/sha256:8daa9615cce30c259a9555b1cc250d461d1bc69980a274b44d7eda0be78076d8\nTEMPLATE \"\"\"[INST] {{ if and .First .System }}&lt;&lt;SYS&gt;&gt;{{ .System }}&lt;&lt;/SYS&gt;&gt;\n\n{{ end }}{{ .Prompt }} [/INST] \"\"\"\nSYSTEM \"\"\"\"\"\"\nPARAMETER stop [INST]\nPARAMETER stop [/INST]\nPARAMETER stop &lt;&lt;SYS&gt;&gt;\nPARAMETER stop &lt;&lt;/SYS&gt;&gt;\n"
            </summary>
            <example>Modelfile generated by \"ollama show\"\n# To build a new Modelfile based on this one, replace the FROM line with:\n# FROM llama3:latest\n\nFROM /Users/username/.ollama/models/blobs/sha256:8daa9615cce30c259a9555b1cc250d461d1bc69980a274b44d7eda0be78076d8\nTEMPLATE \"\"\"[INST] {{ if and .First .System }}&lt;&lt;SYS&gt;&gt;{{ .System }}&lt;&lt;/SYS&gt;&gt;\n\n{{ end }}{{ .Prompt }} [/INST] \"\"\"\nSYSTEM \"\"\"\"\"\"\nPARAMETER stop [INST]\nPARAMETER stop [/INST]\nPARAMETER stop &lt;&lt;SYS&gt;&gt;\nPARAMETER stop &lt;&lt;/SYS&gt;&gt;\n"</example>
        </member>
        <member name="P:Ollama.ModelInfo.Parameters">
            <summary>
            The model parameters.<br/>
            Example: stop [INST]\nstop [/INST]\nstop &lt;&lt;SYS&gt;&gt;\nstop &lt;&lt;/SYS&gt;&gt;
            </summary>
            <example>stop [INST]\nstop [/INST]\nstop &lt;&lt;SYS&gt;&gt;\nstop &lt;&lt;/SYS&gt;&gt;</example>
        </member>
        <member name="P:Ollama.ModelInfo.Template">
            <summary>
            The prompt template for the model.<br/>
            Example: [INST] {{ if and .First .System }}&lt;&lt;SYS&gt;&gt;{{ .System }}&lt;&lt;/SYS&gt;&gt;\n\n{{ end }}{{ .Prompt }} [/INST]
            </summary>
            <example>[INST] {{ if and .First .System }}&lt;&lt;SYS&gt;&gt;{{ .System }}&lt;&lt;/SYS&gt;&gt;\n\n{{ end }}{{ .Prompt }} [/INST]</example>
        </member>
        <member name="P:Ollama.ModelInfo.System">
            <summary>
            The system prompt for the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInfo.Details">
            <summary>
            Details about a model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInfo.ModelInfo1">
            <summary>
            Details about a model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInfo.Messages">
            <summary>
            The default messages for the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInfo.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.#ctor(System.String,System.String,System.String,System.String,System.String,Ollama.ModelDetails,Ollama.ModelInformation,System.Collections.Generic.IList{Ollama.Message})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelInfo" /> class.
            </summary>
            <param name="license">
            The model's license.<br/>
            Example: &lt;contents of license block&gt;
            </param>
            <param name="modelfile">
            The modelfile associated with the model.<br/>
            Example: Modelfile generated by \"ollama show\"\n# To build a new Modelfile based on this one, replace the FROM line with:\n# FROM llama3:latest\n\nFROM /Users/username/.ollama/models/blobs/sha256:8daa9615cce30c259a9555b1cc250d461d1bc69980a274b44d7eda0be78076d8\nTEMPLATE \"\"\"[INST] {{ if and .First .System }}&lt;&lt;SYS&gt;&gt;{{ .System }}&lt;&lt;/SYS&gt;&gt;\n\n{{ end }}{{ .Prompt }} [/INST] \"\"\"\nSYSTEM \"\"\"\"\"\"\nPARAMETER stop [INST]\nPARAMETER stop [/INST]\nPARAMETER stop &lt;&lt;SYS&gt;&gt;\nPARAMETER stop &lt;&lt;/SYS&gt;&gt;\n"
            </param>
            <param name="parameters">
            The model parameters.<br/>
            Example: stop [INST]\nstop [/INST]\nstop &lt;&lt;SYS&gt;&gt;\nstop &lt;&lt;/SYS&gt;&gt;
            </param>
            <param name="template">
            The prompt template for the model.<br/>
            Example: [INST] {{ if and .First .System }}&lt;&lt;SYS&gt;&gt;{{ .System }}&lt;&lt;/SYS&gt;&gt;\n\n{{ end }}{{ .Prompt }} [/INST]
            </param>
            <param name="system">
            The system prompt for the model.
            </param>
            <param name="details">
            Details about a model.
            </param>
            <param name="modelInfo1">
            Details about a model.
            </param>
            <param name="messages">
            The default messages for the model.
            </param>
        </member>
        <member name="M:Ollama.ModelInfo.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelInfo" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfo.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ModelInfoRequest">
            <summary>
            Request class for the show model info endpoint.
            </summary>
        </member>
        <member name="P:Ollama.ModelInfoRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.ModelInfoRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelInfoRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
        </member>
        <member name="M:Ollama.ModelInfoRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelInfoRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInfoRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ModelInformation">
            <summary>
            Details about a model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInformation.GeneralArchitecture">
            <summary>
            The architecture of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInformation.GeneralFileType">
            <summary>
            The file type of the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInformation.GeneralParameterCount">
            <summary>
            The number of parameters in the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInformation.GeneralQuantizationVersion">
            <summary>
            The number of parameters in the model.
            </summary>
        </member>
        <member name="P:Ollama.ModelInformation.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.#ctor(System.String,System.Nullable{System.Int32},System.Nullable{System.Int64},System.Nullable{System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelInformation" /> class.
            </summary>
            <param name="generalArchitecture">
            The architecture of the model.
            </param>
            <param name="generalFileType">
            The file type of the model.
            </param>
            <param name="generalParameterCount">
            The number of parameters in the model.
            </param>
            <param name="generalQuantizationVersion">
            The number of parameters in the model.
            </param>
        </member>
        <member name="M:Ollama.ModelInformation.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelInformation" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelInformation.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ModelsResponse">
            <summary>
            Response class for the list models endpoint.
            </summary>
        </member>
        <member name="P:Ollama.ModelsResponse.Models">
            <summary>
            List of models available locally.
            </summary>
        </member>
        <member name="P:Ollama.ModelsResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.#ctor(System.Collections.Generic.IList{Ollama.Model})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelsResponse" /> class.
            </summary>
            <param name="models">
            List of models available locally.
            </param>
        </member>
        <member name="M:Ollama.ModelsResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ModelsResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ModelsResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ProcessModel">
            <summary>
            A model that is currently loaded.
            </summary>
        </member>
        <member name="P:Ollama.ProcessModel.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.ProcessModel.Size">
            <summary>
            Size of the model on disk.<br/>
            Example: 7323310500L
            </summary>
            <example>7323310500L</example>
        </member>
        <member name="P:Ollama.ProcessModel.Digest">
            <summary>
            The model's digest.<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </summary>
            <example>sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a</example>
        </member>
        <member name="P:Ollama.ProcessModel.Details">
            <summary>
            Details about a model.
            </summary>
        </member>
        <member name="P:Ollama.ProcessModel.ExpiresAt">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.ProcessModel.SizeVram">
            <summary>
            Size of the model on disk.<br/>
            Example: 7323310500L
            </summary>
            <example>7323310500L</example>
        </member>
        <member name="P:Ollama.ProcessModel.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.#ctor(System.String,System.Nullable{System.Int64},System.String,Ollama.ModelDetails,System.Nullable{System.DateTime},System.Nullable{System.Int64})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ProcessModel" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="size">
            Size of the model on disk.<br/>
            Example: 7323310500L
            </param>
            <param name="digest">
            The model's digest.<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </param>
            <param name="details">
            Details about a model.
            </param>
            <param name="expiresAt"></param>
            <param name="sizeVram">
            Size of the model on disk.<br/>
            Example: 7323310500L
            </param>
        </member>
        <member name="M:Ollama.ProcessModel.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ProcessModel" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ProcessModel.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ProcessResponse">
            <summary>
            Response class for the list running models endpoint.
            </summary>
        </member>
        <member name="P:Ollama.ProcessResponse.Models">
            <summary>
            List of running models.
            </summary>
        </member>
        <member name="P:Ollama.ProcessResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.#ctor(System.Collections.Generic.IList{Ollama.ProcessModel})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ProcessResponse" /> class.
            </summary>
            <param name="models">
            List of running models.
            </param>
        </member>
        <member name="M:Ollama.ProcessResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ProcessResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ProcessResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.PullModelRequest">
            <summary>
            Request class for pulling a model.
            </summary>
        </member>
        <member name="P:Ollama.PullModelRequest.Model">
            <summary>
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </summary>
            <example>llama3.2</example>
        </member>
        <member name="P:Ollama.PullModelRequest.Insecure">
            <summary>
            Allow insecure connections to the library. <br/>
            Only use this if you are pulling from your own library during development.<br/>
            Default Value: false
            </summary>
        </member>
        <member name="P:Ollama.PullModelRequest.Username">
            <summary>
            Ollama username.
            </summary>
        </member>
        <member name="P:Ollama.PullModelRequest.Password">
            <summary>
            Ollama password.
            </summary>
        </member>
        <member name="P:Ollama.PullModelRequest.Stream">
            <summary>
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </summary>
        </member>
        <member name="P:Ollama.PullModelRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.#ctor(System.String,System.Nullable{System.Boolean},System.String,System.String,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PullModelRequest" /> class.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="insecure">
            Allow insecure connections to the library. <br/>
            Only use this if you are pulling from your own library during development.<br/>
            Default Value: false
            </param>
            <param name="username">
            Ollama username.
            </param>
            <param name="password">
            Ollama password.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
        </member>
        <member name="M:Ollama.PullModelRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PullModelRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.PullModelResponse">
            <summary>
            Response class for pulling a model. <br/>
            The first object is the manifest. Then there is a series of downloading responses. Until any of the download is completed, the `completed` key may not be included. <br/>
            The number of files to be downloaded depends on the number of layers specified in the manifest.
            </summary>
        </member>
        <member name="P:Ollama.PullModelResponse.Status">
            <summary>
            Status pulling the model.<br/>
            Example: pulling manifest
            </summary>
            <example>pulling manifest</example>
        </member>
        <member name="P:Ollama.PullModelResponse.Digest">
            <summary>
            The model's digest.<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </summary>
            <example>sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a</example>
        </member>
        <member name="P:Ollama.PullModelResponse.Total">
            <summary>
            Total size of the model.<br/>
            Example: 2142590208L
            </summary>
            <example>2142590208L</example>
        </member>
        <member name="P:Ollama.PullModelResponse.Completed">
            <summary>
            Total bytes transferred.<br/>
            Example: 2142590208L
            </summary>
            <example>2142590208L</example>
        </member>
        <member name="P:Ollama.PullModelResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.#ctor(System.Nullable{Ollama.PullModelStatus},System.String,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PullModelResponse" /> class.
            </summary>
            <param name="status">
            Status pulling the model.<br/>
            Example: pulling manifest
            </param>
            <param name="digest">
            The model's digest.<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </param>
            <param name="total">
            Total size of the model.<br/>
            Example: 2142590208L
            </param>
            <param name="completed">
            Total bytes transferred.<br/>
            Example: 2142590208L
            </param>
        </member>
        <member name="M:Ollama.PullModelResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PullModelResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.PullModelStatus">
            <summary>
            Status pulling the model.<br/>
            Example: pulling manifest
            </summary>
        </member>
        <member name="P:Ollama.PullModelStatus.Value1">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.PullModelStatus.IsValue1">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.op_Implicit(System.String)~Ollama.PullModelStatus">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.op_Implicit(Ollama.PullModelStatus)~System.String">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.#ctor(System.String)">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.PullModelStatus.Value2">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.PullModelStatus.IsValue2">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.op_Implicit(Ollama.PullModelStatusEnum)~Ollama.PullModelStatus">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.op_Implicit(Ollama.PullModelStatus)~System.Nullable{Ollama.PullModelStatusEnum}">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.#ctor(System.Nullable{Ollama.PullModelStatusEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.#ctor(System.String,System.Nullable{Ollama.PullModelStatusEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.PullModelStatus.Object">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.Validate">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.Match``1(System.Func{System.String,``0},System.Func{System.Nullable{Ollama.PullModelStatusEnum},``0},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.Match(System.Action{System.String},System.Action{System.Nullable{Ollama.PullModelStatusEnum}},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.GetHashCode">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.Equals(Ollama.PullModelStatus)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.op_Equality(Ollama.PullModelStatus,Ollama.PullModelStatus)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.op_Inequality(Ollama.PullModelStatus,Ollama.PullModelStatus)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.Equals(System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatus.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.PullModelStatusEnum">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PullModelStatusEnum.PullingManifest">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PullModelStatusEnum.DownloadingDigestname">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PullModelStatusEnum.VerifyingSha256Digest">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PullModelStatusEnum.WritingManifest">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PullModelStatusEnum.RemovingAnyUnusedLayers">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PullModelStatusEnum.Success">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.PullModelStatusEnumExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatusEnumExtensions.ToValueString(Ollama.PullModelStatusEnum)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.PullModelStatusEnumExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.PushModelRequest">
            <summary>
            Request class for pushing a model.
            </summary>
        </member>
        <member name="P:Ollama.PushModelRequest.Model">
            <summary>
            The name of the model to push in the form of &lt;namespace&gt;/&lt;model&gt;:&lt;tag&gt;.<br/>
            Example: mattw/pygmalion:latest
            </summary>
            <example>mattw/pygmalion:latest</example>
        </member>
        <member name="P:Ollama.PushModelRequest.Insecure">
            <summary>
            Allow insecure connections to the library. <br/>
            Only use this if you are pushing to your library during development.<br/>
            Default Value: false
            </summary>
        </member>
        <member name="P:Ollama.PushModelRequest.Username">
            <summary>
            Ollama username.
            </summary>
        </member>
        <member name="P:Ollama.PushModelRequest.Password">
            <summary>
            Ollama password.
            </summary>
        </member>
        <member name="P:Ollama.PushModelRequest.Stream">
            <summary>
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </summary>
        </member>
        <member name="P:Ollama.PushModelRequest.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.#ctor(System.String,System.Nullable{System.Boolean},System.String,System.String,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PushModelRequest" /> class.
            </summary>
            <param name="model">
            The name of the model to push in the form of &lt;namespace&gt;/&lt;model&gt;:&lt;tag&gt;.<br/>
            Example: mattw/pygmalion:latest
            </param>
            <param name="insecure">
            Allow insecure connections to the library. <br/>
            Only use this if you are pushing to your library during development.<br/>
            Default Value: false
            </param>
            <param name="username">
            Ollama username.
            </param>
            <param name="password">
            Ollama password.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
        </member>
        <member name="M:Ollama.PushModelRequest.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PushModelRequest" /> class.
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PushModelRequest.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.PushModelResponse">
            <summary>
            Response class for pushing a model.
            </summary>
        </member>
        <member name="P:Ollama.PushModelResponse.Status">
            <summary>
            Status pushing the model.
            </summary>
        </member>
        <member name="P:Ollama.PushModelResponse.Digest">
            <summary>
            the model's digest<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </summary>
            <example>sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a</example>
        </member>
        <member name="P:Ollama.PushModelResponse.Total">
            <summary>
            total size of the model<br/>
            Example: 2142590208L
            </summary>
            <example>2142590208L</example>
        </member>
        <member name="P:Ollama.PushModelResponse.Completed">
            <summary>
            Total bytes transferred.<br/>
            Example: 2142590208L
            </summary>
            <example>2142590208L</example>
        </member>
        <member name="P:Ollama.PushModelResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.#ctor(System.Nullable{Ollama.AnyOf{System.String,System.Nullable{Ollama.PushModelResponseStatus}}},System.String,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PushModelResponse" /> class.
            </summary>
            <param name="status">
            Status pushing the model.
            </param>
            <param name="digest">
            the model's digest<br/>
            Example: sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711a
            </param>
            <param name="total">
            total size of the model<br/>
            Example: 2142590208L
            </param>
            <param name="completed">
            Total bytes transferred.<br/>
            Example: 2142590208L
            </param>
        </member>
        <member name="M:Ollama.PushModelResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PushModelResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.PushModelResponseStatus">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PushModelResponseStatus.RetrievingManifest">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PushModelResponseStatus.StartingUpload">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PushModelResponseStatus.PushingManifest">
            <summary>
            
            </summary>
        </member>
        <member name="F:Ollama.PushModelResponseStatus.Success">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.PushModelResponseStatusExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponseStatusExtensions.ToValueString(Ollama.PushModelResponseStatus)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.PushModelResponseStatusExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.RequestOptions">
            <summary>
            Additional model parameters listed in the documentation for the Modelfile such as `temperature`.
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.NumKeep">
            <summary>
            Number of tokens to keep from the prompt.
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.Seed">
            <summary>
            Sets the random number seed to use for generation. Setting this to a specific number will make the model <br/>
            generate the same text for the same prompt. (Default: 0)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.NumPredict">
            <summary>
            Maximum number of tokens to predict when generating text. <br/>
            (Default: 128, -1 = infinite generation, -2 = fill context)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.TopK">
            <summary>
            Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, <br/>
            while a lower value (e.g. 10) will be more conservative. (Default: 40)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.TopP">
            <summary>
            Works together with top_k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value <br/>
            (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.MinP">
            <summary>
            Alternative to the top_p, and aims to ensure a balance of quality and variety. min_p represents the minimum <br/>
            probability for a token to be considered, relative to the probability of the most likely token. For <br/>
            example, with min_p=0.05 and the most likely token having a probability of 0.9, logits with a value less <br/>
            than 0.05*0.9=0.045 are filtered out. (Default: 0.0)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.TfsZ">
            <summary>
            Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value <br/>
            (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (default: 1)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.TypicalP">
            <summary>
            Typical p is used to reduce the impact of less probable tokens from the output. (default: 1)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.RepeatLastN">
            <summary>
            Sets how far back for the model to look back to prevent repetition. <br/>
            (Default: 64, 0 = disabled, -1 = num_ctx)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.Temperature">
            <summary>
            The temperature of the model. Increasing the temperature will make the model answer more creatively. <br/>
            (Default: 0.8)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.RepeatPenalty">
            <summary>
            Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more <br/>
            strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.PresencePenalty">
            <summary>
            Positive values penalize new tokens based on whether they appear in the text so far, increasing the <br/>
            model's likelihood to talk about new topics. (Default: 0)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.FrequencyPenalty">
            <summary>
            Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the <br/>
            model's likelihood to repeat the same line verbatim. (Default: 0)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.Mirostat">
            <summary>
            Enable Mirostat sampling for controlling perplexity. <br/>
            (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.MirostatTau">
            <summary>
            Controls the balance between coherence and diversity of the output. A lower value will result in more <br/>
            focused and coherent text. (Default: 5.0)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.MirostatEta">
            <summary>
            Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate <br/>
            will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. <br/>
            (Default: 0.1)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.PenalizeNewline">
            <summary>
            Penalize newlines in the output. (Default: true)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.Stop">
            <summary>
            Sequences where the API will stop generating further tokens. The returned text will not contain the stop <br/>
            sequence.
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.Numa">
            <summary>
            Enable NUMA support. (Default: false)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.NumCtx">
            <summary>
            Sets the size of the context window used to generate the next token. (Default: 2048)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.NumBatch">
            <summary>
            Sets the number of batches to use for generation. (Default: 512)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.NumGpu">
            <summary>
            The number of layers to send to the GPU(s). <br/>
            On macOS it defaults to 1 to enable metal support, 0 to disable.
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.MainGpu">
            <summary>
            The GPU to use for the main model. Default is 0.
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.LowVram">
            <summary>
            Enable low VRAM mode. (Default: false)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.F16Kv">
            <summary>
            Enable f16 key/value. (Default: true)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.LogitsAll">
            <summary>
            Enable logits all. (Default: false)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.VocabOnly">
            <summary>
            Enable vocab only. (Default: false)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.UseMmap">
            <summary>
            Enable mmap. (Default: false)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.UseMlock">
            <summary>
            Enable mlock. (Default: false)
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.NumThread">
            <summary>
            Sets the number of threads to use during computation. By default, Ollama will detect this for optimal <br/>
            performance. It is recommended to set this value to the number of physical CPU cores your system has <br/>
            (as opposed to the logical number of cores).
            </summary>
        </member>
        <member name="P:Ollama.RequestOptions.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.#ctor(System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Collections.Generic.IList{System.String},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.RequestOptions" /> class.
            </summary>
            <param name="numKeep">
            Number of tokens to keep from the prompt.
            </param>
            <param name="seed">
            Sets the random number seed to use for generation. Setting this to a specific number will make the model <br/>
            generate the same text for the same prompt. (Default: 0)
            </param>
            <param name="numPredict">
            Maximum number of tokens to predict when generating text. <br/>
            (Default: 128, -1 = infinite generation, -2 = fill context)
            </param>
            <param name="topK">
            Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, <br/>
            while a lower value (e.g. 10) will be more conservative. (Default: 40)
            </param>
            <param name="topP">
            Works together with top_k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value <br/>
            (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)
            </param>
            <param name="minP">
            Alternative to the top_p, and aims to ensure a balance of quality and variety. min_p represents the minimum <br/>
            probability for a token to be considered, relative to the probability of the most likely token. For <br/>
            example, with min_p=0.05 and the most likely token having a probability of 0.9, logits with a value less <br/>
            than 0.05*0.9=0.045 are filtered out. (Default: 0.0)
            </param>
            <param name="tfsZ">
            Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value <br/>
            (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (default: 1)
            </param>
            <param name="typicalP">
            Typical p is used to reduce the impact of less probable tokens from the output. (default: 1)
            </param>
            <param name="repeatLastN">
            Sets how far back for the model to look back to prevent repetition. <br/>
            (Default: 64, 0 = disabled, -1 = num_ctx)
            </param>
            <param name="temperature">
            The temperature of the model. Increasing the temperature will make the model answer more creatively. <br/>
            (Default: 0.8)
            </param>
            <param name="repeatPenalty">
            Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more <br/>
            strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1)
            </param>
            <param name="presencePenalty">
            Positive values penalize new tokens based on whether they appear in the text so far, increasing the <br/>
            model's likelihood to talk about new topics. (Default: 0)
            </param>
            <param name="frequencyPenalty">
            Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the <br/>
            model's likelihood to repeat the same line verbatim. (Default: 0)
            </param>
            <param name="mirostat">
            Enable Mirostat sampling for controlling perplexity. <br/>
            (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)
            </param>
            <param name="mirostatTau">
            Controls the balance between coherence and diversity of the output. A lower value will result in more <br/>
            focused and coherent text. (Default: 5.0)
            </param>
            <param name="mirostatEta">
            Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate <br/>
            will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. <br/>
            (Default: 0.1)
            </param>
            <param name="penalizeNewline">
            Penalize newlines in the output. (Default: true)
            </param>
            <param name="stop">
            Sequences where the API will stop generating further tokens. The returned text will not contain the stop <br/>
            sequence.
            </param>
            <param name="numa">
            Enable NUMA support. (Default: false)
            </param>
            <param name="numCtx">
            Sets the size of the context window used to generate the next token. (Default: 2048)
            </param>
            <param name="numBatch">
            Sets the number of batches to use for generation. (Default: 512)
            </param>
            <param name="numGpu">
            The number of layers to send to the GPU(s). <br/>
            On macOS it defaults to 1 to enable metal support, 0 to disable.
            </param>
            <param name="mainGpu">
            The GPU to use for the main model. Default is 0.
            </param>
            <param name="lowVram">
            Enable low VRAM mode. (Default: false)
            </param>
            <param name="f16Kv">
            Enable f16 key/value. (Default: true)
            </param>
            <param name="logitsAll">
            Enable logits all. (Default: false)
            </param>
            <param name="vocabOnly">
            Enable vocab only. (Default: false)
            </param>
            <param name="useMmap">
            Enable mmap. (Default: false)
            </param>
            <param name="useMlock">
            Enable mlock. (Default: false)
            </param>
            <param name="numThread">
            Sets the number of threads to use during computation. By default, Ollama will detect this for optimal <br/>
            performance. It is recommended to set this value to the number of physical CPU cores your system has <br/>
            (as opposed to the logical number of cores).
            </param>
        </member>
        <member name="M:Ollama.RequestOptions.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.RequestOptions" /> class.
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.RequestOptions.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ResponseFormat">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.ResponseFormat.Value1">
            <summary>
            Enable JSON mode by setting the format parameter to 'json'. This will structure the response as valid JSON.
            </summary>
        </member>
        <member name="P:Ollama.ResponseFormat.IsValue1">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.op_Implicit(Ollama.ResponseFormatEnum)~Ollama.ResponseFormat">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.op_Implicit(Ollama.ResponseFormat)~System.Nullable{Ollama.ResponseFormatEnum}">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.#ctor(System.Nullable{Ollama.ResponseFormatEnum})">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.ResponseFormat.Value2">
            <summary>
            A JSON Schema object that defines the structure of the response. The model will generate a response that matches this schema.
            </summary>
        </member>
        <member name="P:Ollama.ResponseFormat.IsValue2">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.#ctor(System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.#ctor(System.Nullable{Ollama.ResponseFormatEnum},System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.ResponseFormat.Object">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.Validate">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.Match``1(System.Func{System.Nullable{Ollama.ResponseFormatEnum},``0},System.Func{System.Object,``0},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.Match(System.Action{System.Nullable{Ollama.ResponseFormatEnum}},System.Action{System.Object},System.Boolean)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.GetHashCode">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.Equals(Ollama.ResponseFormat)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.op_Equality(Ollama.ResponseFormat,Ollama.ResponseFormat)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.op_Inequality(Ollama.ResponseFormat,Ollama.ResponseFormat)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.Equals(System.Object)">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormat.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ResponseFormatEnum">
            <summary>
            Enable JSON mode by setting the format parameter to 'json'. This will structure the response as valid JSON.
            </summary>
        </member>
        <member name="F:Ollama.ResponseFormatEnum.Json">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.ResponseFormatEnumExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnumExtensions.ToValueString(Ollama.ResponseFormatEnum)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnumExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.ResponseFormatEnum2">
            <summary>
            A JSON Schema object that defines the structure of the response. The model will generate a response that matches this schema.
            </summary>
        </member>
        <member name="P:Ollama.ResponseFormatEnum2.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnum2.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnum2.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnum2.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnum2.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnum2.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ResponseFormatEnum2.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.Tool">
            <summary>
            A tool the model may call.
            </summary>
        </member>
        <member name="P:Ollama.Tool.Type">
            <summary>
            The type of tool.<br/>
            Default Value: function
            </summary>
        </member>
        <member name="P:Ollama.Tool.Function">
            <summary>
            A function that the model may call.
            </summary>
        </member>
        <member name="P:Ollama.Tool.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.Tool.#ctor(System.Nullable{Ollama.ToolType},Ollama.ToolFunction)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.Tool" /> class.
            </summary>
            <param name="type">
            The type of tool.<br/>
            Default Value: function
            </param>
            <param name="function">
            A function that the model may call.
            </param>
        </member>
        <member name="M:Ollama.Tool.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.Tool" /> class.
            </summary>
        </member>
        <member name="M:Ollama.Tool.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Tool.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Tool.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Tool.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.Tool.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.Tool.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ToolCall">
            <summary>
            The tool the model wants to call.
            </summary>
        </member>
        <member name="P:Ollama.ToolCall.Function">
            <summary>
            The function the model wants to call.
            </summary>
        </member>
        <member name="P:Ollama.ToolCall.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.#ctor(Ollama.ToolCallFunction)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ToolCall" /> class.
            </summary>
            <param name="function">
            The function the model wants to call.
            </param>
        </member>
        <member name="M:Ollama.ToolCall.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ToolCall" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCall.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ToolCallFunction">
            <summary>
            The function the model wants to call.
            </summary>
        </member>
        <member name="P:Ollama.ToolCallFunction.Name">
            <summary>
            The name of the function to be called.
            </summary>
        </member>
        <member name="P:Ollama.ToolCallFunction.Arguments">
            <summary>
            The arguments to pass to the function.
            </summary>
        </member>
        <member name="P:Ollama.ToolCallFunction.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.#ctor(System.String,System.Object)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ToolCallFunction" /> class.
            </summary>
            <param name="name">
            The name of the function to be called.
            </param>
            <param name="arguments">
            The arguments to pass to the function.
            </param>
        </member>
        <member name="M:Ollama.ToolCallFunction.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ToolCallFunction" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunction.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ToolCallFunctionArgs">
            <summary>
            The arguments to pass to the function.
            </summary>
        </member>
        <member name="P:Ollama.ToolCallFunctionArgs.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunctionArgs.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunctionArgs.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunctionArgs.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunctionArgs.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunctionArgs.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolCallFunctionArgs.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ToolFunction">
            <summary>
            A function that the model may call.
            </summary>
        </member>
        <member name="P:Ollama.ToolFunction.Name">
            <summary>
            The name of the function to be called.
            </summary>
        </member>
        <member name="P:Ollama.ToolFunction.Description">
            <summary>
            A description of what the function does, used by the model to choose when and how to call the function.
            </summary>
        </member>
        <member name="P:Ollama.ToolFunction.Parameters">
            <summary>
            The parameters the functions accepts, described as a JSON Schema object.
            </summary>
        </member>
        <member name="P:Ollama.ToolFunction.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.#ctor(System.String,System.String,System.Object)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ToolFunction" /> class.
            </summary>
            <param name="name">
            The name of the function to be called.
            </param>
            <param name="description">
            A description of what the function does, used by the model to choose when and how to call the function.
            </param>
            <param name="parameters">
            The parameters the functions accepts, described as a JSON Schema object.
            </param>
        </member>
        <member name="M:Ollama.ToolFunction.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.ToolFunction" /> class.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunction.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ToolFunctionParams">
            <summary>
            The parameters the functions accepts, described as a JSON Schema object.
            </summary>
        </member>
        <member name="P:Ollama.ToolFunctionParams.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.ToolFunctionParams.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunctionParams.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunctionParams.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunctionParams.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunctionParams.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.ToolFunctionParams.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ToolType">
            <summary>
            The type of tool.<br/>
            Default Value: function
            </summary>
        </member>
        <member name="F:Ollama.ToolType.Function">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.ToolTypeExtensions">
            <summary>
            Enum extensions to do fast conversions without the reflection.
            </summary>
        </member>
        <member name="M:Ollama.ToolTypeExtensions.ToValueString(Ollama.ToolType)">
            <summary>
            Converts an enum to a string.
            </summary>
        </member>
        <member name="M:Ollama.ToolTypeExtensions.ToEnum(System.String)">
            <summary>
            Converts an string to a enum.
            </summary>
        </member>
        <member name="T:Ollama.VersionResponse">
            <summary>
            The response class for the version endpoint.
            </summary>
        </member>
        <member name="P:Ollama.VersionResponse.Version">
            <summary>
            The version of the Ollama server.
            </summary>
        </member>
        <member name="P:Ollama.VersionResponse.AdditionalProperties">
            <summary>
            Additional properties that are not explicitly defined in the schema
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.VersionResponse" /> class.
            </summary>
            <param name="version">
            The version of the Ollama server.
            </param>
        </member>
        <member name="M:Ollama.VersionResponse.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.VersionResponse" /> class.
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.ToJson(System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.ToJson(System.Text.Json.JsonSerializerOptions)">
            <summary>
            Serializes the current instance to a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.FromJson(System.String,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.FromJson(System.String,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON string using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.Serialization.JsonSerializerContext)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerContext.
            </summary>
        </member>
        <member name="M:Ollama.VersionResponse.FromJsonStreamAsync(System.IO.Stream,System.Text.Json.JsonSerializerOptions)">
            <summary>
            Deserializes a JSON stream using the provided JsonSerializerOptions.
            </summary>
        </member>
        <member name="T:Ollama.ModelsClient">
            <summary>
            List and describe the various models available.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="M:Ollama.ModelsClient.CheckBlobAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Ensures that the file blob used for a FROM or ADAPTER field exists on the server.<br/>
            This is checking your Ollama server and not Ollama.ai.
            </summary>
            <param name="digest"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.CopyModelAsync(Ollama.CopyModelRequest,System.Threading.CancellationToken)">
            <summary>
            Creates a model with another name from an existing model.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.CopyModelAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary>
            Creates a model with another name from an existing model.
            </summary>
            <param name="source">
            Name of the model to copy.<br/>
            Example: llama3.2
            </param>
            <param name="destination">
            Name of the new model.<br/>
            Example: llama3-backup
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.CreateBlobAsync(System.String,System.Byte[],System.Threading.CancellationToken)">
            <summary>
            Create a blob from a file. Returns the server file path.
            </summary>
            <param name="digest"></param>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.CreateBlobAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Create a blob from a file. Returns the server file path.
            </summary>
            <param name="digest"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.CreateModelAsync(Ollama.CreateModelRequest,System.Threading.CancellationToken)">
            <summary>
            Create a model from a Modelfile.<br/>
            It is recommended to set `modelfile` to the content of the Modelfile rather than just set `path`. This is a requirement for remote create. Remote model creation should also create any file blobs, fields such as `FROM` and `ADAPTER`, explicitly with the server using Create a Blob and the value to the path indicated in the response.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.CreateModelAsync(System.String,System.String,System.String,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            Create a model from a Modelfile.<br/>
            It is recommended to set `modelfile` to the content of the Modelfile rather than just set `path`. This is a requirement for remote create. Remote model creation should also create any file blobs, fields such as `FROM` and `ADAPTER`, explicitly with the server using Create a Blob and the value to the path indicated in the response.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: mario
            </param>
            <param name="modelfile">
            The contents of the Modelfile.<br/>
            Example: FROM llama3\nSYSTEM You are mario from Super Mario Bros.
            </param>
            <param name="path">
            Path to the Modelfile (optional)
            </param>
            <param name="quantize">
            The quantization level of the model.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.DeleteModelAsync(Ollama.DeleteModelRequest,System.Threading.CancellationToken)">
            <summary>
            Delete a model and its data.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.DeleteModelAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Delete a model and its data.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3:13b
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="F:Ollama.ModelsClient.DefaultBaseUrl">
            <summary>
            Ollama server URL
            </summary>
        </member>
        <member name="P:Ollama.ModelsClient.HttpClient">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ModelsClient.BaseUri">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ModelsClient.Authorizations">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ModelsClient.ReadResponseAsString">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.ModelsClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.ModelsClient.#ctor(System.Net.Http.HttpClient,System.Uri,System.Collections.Generic.List{Ollama.EndPointAuthorization},System.Boolean)">
            <summary>
            Creates a new instance of the ModelsClient.
            If no httpClient is provided, a new one will be created.
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
            <param name="httpClient">The HttpClient instance. If not provided, a new one will be created.</param>
            <param name="baseUri">The base URL for the API. If not provided, the default baseUri from OpenAPI spec will be used.</param>
            <param name="authorizations">The authorizations to use for the requests.</param>
            <param name="disposeHttpClient">Dispose the HttpClient when the instance is disposed. True by default.</param>
        </member>
        <member name="M:Ollama.ModelsClient.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.ModelsClient.ListModelsAsync(System.Threading.CancellationToken)">
            <summary>
            List models that are available locally.
            </summary>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.ListRunningModelsAsync(System.Threading.CancellationToken)">
            <summary>
            List models that are running.
            </summary>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.PullModelAsync(Ollama.PullModelRequest,System.Threading.CancellationToken)">
            <summary>
            Download a model from the ollama library.<br/>
            Cancelled pulls are resumed from where they left off, and multiple calls will share the same download progress.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.PullModelAsync(System.String,System.Nullable{System.Boolean},System.String,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            Download a model from the ollama library.<br/>
            Cancelled pulls are resumed from where they left off, and multiple calls will share the same download progress.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="insecure">
            Allow insecure connections to the library. <br/>
            Only use this if you are pulling from your own library during development.<br/>
            Default Value: false
            </param>
            <param name="username">
            Ollama username.
            </param>
            <param name="password">
            Ollama password.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.PushModelAsync(Ollama.PushModelRequest,System.Threading.CancellationToken)">
            <summary>
            Upload a model to a model library.<br/>
            Requires registering for ollama.ai and adding a public key first.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.PushModelAsync(System.String,System.Nullable{System.Boolean},System.String,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            Upload a model to a model library.<br/>
            Requires registering for ollama.ai and adding a public key first.
            </summary>
            <param name="model">
            The name of the model to push in the form of &lt;namespace&gt;/&lt;model&gt;:&lt;tag&gt;.<br/>
            Example: mattw/pygmalion:latest
            </param>
            <param name="insecure">
            Allow insecure connections to the library. <br/>
            Only use this if you are pushing to your library during development.<br/>
            Default Value: false
            </param>
            <param name="username">
            Ollama username.
            </param>
            <param name="password">
            Ollama password.
            </param>
            <param name="stream">
            If `false` the response will be returned as a single response object, otherwise the response will be streamed as a series of objects.<br/>
            Default Value: true
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.ShowModelInfoAsync(Ollama.ModelInfoRequest,System.Threading.CancellationToken)">
            <summary>
            Show details about a model including modelfile, template, parameters, license, and system prompt.
            </summary>
            <param name="request"></param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="M:Ollama.ModelsClient.ShowModelInfoAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Show details about a model including modelfile, template, parameters, license, and system prompt.
            </summary>
            <param name="model">
            The model name. <br/>
            Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.<br/>
            Example: llama3.2
            </param>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="T:Ollama.OllamaApiClient">
            <summary>
            API Spec for Ollama API. Please see https://github.com/jmorganca/ollama/blob/main/docs/api.md for more details.<br/>
            If no httpClient is provided, a new one will be created.<br/>
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
        </member>
        <member name="F:Ollama.OllamaApiClient.DefaultBaseUrl">
            <summary>
            Ollama server URL
            </summary>
        </member>
        <member name="P:Ollama.OllamaApiClient.HttpClient">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.OllamaApiClient.BaseUri">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.OllamaApiClient.Authorizations">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.OllamaApiClient.ReadResponseAsString">
            <inheritdoc/>
        </member>
        <member name="P:Ollama.OllamaApiClient.JsonSerializerContext">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.OllamaApiClient.Completions">
            <summary>
            Given a prompt, the model will generate a completion.
            </summary>
        </member>
        <member name="P:Ollama.OllamaApiClient.Chat">
            <summary>
            Given a list of messages comprising a conversation, the model will return a response.
            </summary>
        </member>
        <member name="P:Ollama.OllamaApiClient.Embeddings">
            <summary>
            Get a vector representation of a given input.
            </summary>
        </member>
        <member name="P:Ollama.OllamaApiClient.Models">
            <summary>
            List and describe the various models available.
            </summary>
        </member>
        <member name="M:Ollama.OllamaApiClient.#ctor(System.Net.Http.HttpClient,System.Uri,System.Collections.Generic.List{Ollama.EndPointAuthorization},System.Boolean)">
            <summary>
            Creates a new instance of the OllamaApiClient.
            If no httpClient is provided, a new one will be created.
            If no baseUri is provided, the default baseUri from OpenAPI spec will be used.
            </summary>
            <param name="httpClient">The HttpClient instance. If not provided, a new one will be created.</param>
            <param name="baseUri">The base URL for the API. If not provided, the default baseUri from OpenAPI spec will be used.</param>
            <param name="authorizations">The authorizations to use for the requests.</param>
            <param name="disposeHttpClient">Dispose the HttpClient when the instance is disposed. True by default.</param>
        </member>
        <member name="M:Ollama.OllamaApiClient.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Ollama.OllamaApiClient.GetVersionAsync(System.Threading.CancellationToken)">
            <summary>
            Returns the version of the Ollama server.<br/>
            This endpoint returns the version of the Ollama server.
            </summary>
            <param name="cancellationToken">The token to cancel the operation with</param>
            <exception cref="T:Ollama.ApiException"></exception>
        </member>
        <member name="T:Ollama.PathBuilder">
            <summary>
            A helper class to build URL paths with optional and required parameters.
            </summary>
        </member>
        <member name="M:Ollama.PathBuilder.#ctor(System.String,System.Uri)">
            <summary>
            Initializes a new instance of the <see cref="T:Ollama.PathBuilder"/> class.
            </summary>
            <param name="path">The base path for the URL.</param>
            <param name="baseUri">The base URI to prepend to the path, if any.</param>
        </member>
        <member name="M:Ollama.PathBuilder.AddRequiredParameter(System.String,System.String)">
            <summary>
            Adds a required parameter to the URL.
            </summary>
            <param name="name">The name of the parameter.</param>
            <param name="value">The value of the parameter.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddRequiredParameter(System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.Boolean)">
            <summary>
            Adds a required parameter with multiple values to the URL.
            </summary>
            <param name="name">The name of the parameter.</param>
            <param name="value">The values of the parameter.</param>
            <param name="delimiter">The delimiter to use between values.</param>
            <param name="explode">Whether to explode the values into separate parameters.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddRequiredParameter``1(System.String,System.Collections.Generic.IEnumerable{``0},System.Func{``0,System.String},System.String,System.Boolean)">
            <summary>
            Adds a required parameter with multiple values to the URL, using a selector function.
            </summary>
            <typeparam name="T">The type of the values.</typeparam>
            <param name="name">The name of the parameter.</param>
            <param name="value">The values of the parameter.</param>
            <param name="selector">The function to select the string representation of each value.</param>
            <param name="delimiter">The delimiter to use between values.</param>
            <param name="explode">Whether to explode the values into separate parameters.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddOptionalParameter(System.String,System.String)">
            <summary>
            Adds an optional parameter to the URL.
            </summary>
            <param name="name">The name of the parameter.</param>
            <param name="value">The value of the parameter, or null if not present.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddOptionalParameter(System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.Boolean)">
            <summary>
            Adds an optional parameter with multiple values to the URL.
            </summary>
            <param name="name">The name of the parameter.</param>
            <param name="value">The values of the parameter, or null if not present.</param>
            <param name="delimiter">The delimiter to use between values.</param>
            <param name="explode">Whether to explode the values into separate parameters.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddOptionalParameter``1(System.String,System.Collections.Generic.IEnumerable{``0},System.Func{``0,System.String},System.String,System.Boolean)">
            <summary>
            Adds an optional parameter with multiple values to the URL, using a selector function.
            </summary>
            <typeparam name="T">The type of the values.</typeparam>
            <param name="name">The name of the parameter.</param>
            <param name="value">The values of the parameter, or null if not present.</param>
            <param name="selector">The function to select the string representation of each value.</param>
            <param name="delimiter">The delimiter to use between values.</param>
            <param name="explode">Whether to explode the values into separate parameters.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddRequiredParameter``1(System.String,``0,System.String,System.IFormatProvider)">
            <summary>
            Adds a required parameter to the URL, using a formattable value.
            </summary>
            <typeparam name="T">The type of the value.</typeparam>
            <param name="name">The name of the parameter.</param>
            <param name="value">The value of the parameter.</param>
            <param name="format">The format string.</param>
            <param name="formatProvider">The format provider.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.AddOptionalParameter``1(System.String,``0,System.String,System.IFormatProvider)">
            <summary>
            Adds an optional parameter to the URL, using a formattable value.
            </summary>
            <typeparam name="T">The type of the value.</typeparam>
            <param name="name">The name of the parameter.</param>
            <param name="value">The value of the parameter, or null if not present.</param>
            <param name="format">The format string.</param>
            <param name="formatProvider">The format provider.</param>
            <returns>The current <see cref="T:Ollama.PathBuilder"/> instance.</returns>
        </member>
        <member name="M:Ollama.PathBuilder.ToString">
            <summary>
            Returns the constructed URL as a string.
            </summary>
            <returns>The constructed URL.</returns>
        </member>
        <member name="T:Ollama.EndPointAuthorization">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.EndPointAuthorization.Type">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.EndPointAuthorization.Location">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.EndPointAuthorization.Name">
            <summary>
            
            </summary>
        </member>
        <member name="P:Ollama.EndPointAuthorization.Value">
            <summary>
            
            </summary>
        </member>
        <member name="T:Ollama.AutoSdkPolyfills">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.AutoSdkPolyfills.ReadAsStringAsync(System.Net.Http.HttpContent,System.Threading.CancellationToken)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <param name="cancellationToken"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.AutoSdkPolyfills.ReadAsStreamAsync(System.Net.Http.HttpContent,System.Threading.CancellationToken)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <param name="cancellationToken"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.AutoSdkPolyfills.ReadAsByteArrayAsync(System.Net.Http.HttpContent,System.Threading.CancellationToken)">
            <summary>
            
            </summary>
            <param name="content"></param>
            <param name="cancellationToken"></param>
            <returns></returns>
        </member>
        <member name="T:Ollama.OllamaApiClientExtensions">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.Chat(Ollama.OllamaApiClient,System.String,System.String,System.Boolean)">
            <summary>
            Starts a new chat with the currently selected model.
            </summary>
            <param name="client">The client to start the chat with</param>
            <param name="model">The model to chat with</param>
            <param name="systemMessage">Optional. A system message to send to the model</param>
            <param name="autoCallTools">Optional. If set to true, the client will automatically call tools.</param>
            <returns>
            A chat instance that can be used to receive and send messages from and to
            the Ollama endpoint while maintaining the message history.
            </returns>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.EnsureSuccessAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.PullModelResponse})">
            <summary>
            Pulls the specified model from the server and ensures the operation was successful. <br/>
            Safe to call if model already exists. <br/>
            </summary>
            <exception cref="T:System.ArgumentNullException">Thrown when the enumerable is null.</exception>
            <exception cref="T:System.InvalidOperationException">Thrown when the response status is not "success".</exception>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.EnsureSuccess(Ollama.PullModelResponse)">
            <summary>
            Throws an InvalidOperationException if the response is not successful.
            </summary>
            <param name="response"></param>
            <exception cref="T:System.ArgumentNullException"></exception>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.WaitAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.GenerateCompletionResponse})">
            <summary>
            Waits for the enumerable to complete and combines the responses into a single response.
            </summary>
            <param name="enumerable"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.GetAwaiter(System.Collections.Generic.IAsyncEnumerable{Ollama.GenerateCompletionResponse})">
            <inheritdoc cref="M:Ollama.OllamaApiClientExtensions.WaitAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.GenerateCompletionResponse})"/>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.WaitAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.GenerateChatCompletionResponse})">
            <summary>
            Waits for the enumerable to complete and combines the responses into a single response.
            </summary>
            <param name="enumerable"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.GetAwaiter(System.Collections.Generic.IAsyncEnumerable{Ollama.GenerateChatCompletionResponse})">
            <inheritdoc cref="M:Ollama.OllamaApiClientExtensions.WaitAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.GenerateChatCompletionResponse})"/>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.WaitAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.PullModelResponse})">
            <summary>
            Waits for the enumerable to complete and returns the responses.
            </summary>
            <param name="enumerable"></param>
            <returns></returns>
        </member>
        <member name="M:Ollama.OllamaApiClientExtensions.GetAwaiter(System.Collections.Generic.IAsyncEnumerable{Ollama.PullModelResponse})">
            <inheritdoc cref="M:Ollama.OllamaApiClientExtensions.WaitAsync(System.Collections.Generic.IAsyncEnumerable{Ollama.PullModelResponse})"/>
        </member>
        <member name="T:Ollama.PullModelResponseExtensions">
            <summary>
            
            </summary>
        </member>
        <member name="M:Ollama.PullModelResponseExtensions.GetPercent(Ollama.PullModelResponse)">
            <summary>
            
            </summary>
            <param name="response"></param>
            <returns></returns>
            <exception cref="T:System.ArgumentNullException"></exception>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.AllowNullAttribute">
            <summary>
            Specifies that null is allowed as an input even if the corresponding type disallows it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.ConstantExpectedAttribute">
            <summary>
            Indicates that the specified method parameter expects a constant.
            </summary>
            <remarks>
            This can be used to inform tooling that a constant should be used as an argument for the annotated parameter.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.ConstantExpectedAttribute.Min">
            <summary>
            Indicates the minimum bound of the expected constant, inclusive.
            </summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.ConstantExpectedAttribute.Max">
            <summary>
            Indicates the maximum bound of the expected constant, inclusive.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DisallowNullAttribute">
            <summary>
            Specifies that null is disallowed as an input even if the corresponding type allows it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DoesNotReturnAttribute">
            <summary>
            Applied to a method that will never return under any circumstance.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DoesNotReturnIfAttribute">
            <summary>
            Specifies that the method will not return if the associated Boolean parameter is passed the specified value.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DoesNotReturnIfAttribute.#ctor(System.Boolean)">
            <summary>
            Initializes the attribute with the specified parameter value.
            </summary>
            <param name="parameterValue">
            The condition parameter value. Code after the method will be considered unreachable
            by diagnostics if the argument to the associated parameter matches this value.
            </param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DoesNotReturnIfAttribute.ParameterValue">
            <summary>
            Gets the condition parameter value.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.ExperimentalAttribute">
            <summary>
            Indicates that an API is experimental and it may change in the future.
            </summary>
            <remarks>
            This attribute allows call sites to be flagged with a diagnostic that indicates that an experimental
            feature is used. Authors can use this attribute to ship preview features in their assemblies.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.ExperimentalAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.ExperimentalAttribute"/> class,
            specifying the ID that the compiler will use when reporting a use of the API the attribute applies to.
            </summary>
            <param name="diagnosticId">The ID that the compiler will use when reporting a use of the API the attribute applies to.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.ExperimentalAttribute.DiagnosticId">
            <summary>
            Gets the ID that the compiler will use when reporting a use of the API the attribute applies to.
            </summary>
            <value>The unique diagnostic ID.</value>
            <remarks>
            The diagnostic ID is shown in build output for warnings and errors.
            <para>This property represents the unique ID that can be used to suppress the warnings or errors, if needed.</para>
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.ExperimentalAttribute.UrlFormat">
            <summary>
            Gets or sets the URL for corresponding documentation.
            The API accepts a format string instead of an actual URL, creating a generic URL that includes the diagnostic ID.
            </summary>
            <value>The format string that represents a URL to corresponding documentation.</value>
            <remarks>An example format string is <c>https://contoso.com/obsoletion-warnings/{0}</c>.</remarks>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.MaybeNullAttribute">
            <summary>
            Specifies that an output may be null even if the corresponding type disallows it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.MaybeNullWhenAttribute">
            <summary>
            Specifies that when a method returns <see cref="P:System.Diagnostics.CodeAnalysis.MaybeNullWhenAttribute.ReturnValue"/>, the parameter may be null even if the corresponding type disallows it.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.MaybeNullWhenAttribute.#ctor(System.Boolean)">
            <summary>
            Initializes the attribute with the specified return value condition.
            </summary>
            <param name="returnValue">The return value condition. If the method returns this value, the associated parameter may be null.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.MaybeNullWhenAttribute.ReturnValue">
            <summary>
            Gets the return value condition.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.MemberNotNullAttribute">
            <summary>
            Specifies that the method or property will ensure that the listed field and property members have not-null values.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.MemberNotNullAttribute.#ctor(System.String)">
            <summary>
            Initializes the attribute with a field or property member.
            </summary>
            <param name="member">The field or property member that is promised to be not-null.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.MemberNotNullAttribute.#ctor(System.String[])">
            <summary>
            Initializes the attribute with the list of field and property members.
            </summary>
            <param name="members">The list of field and property members that are promised to be not-null.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.MemberNotNullAttribute.Members">
            <summary>
            Gets field or property member names.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.MemberNotNullWhenAttribute">
            <summary>
            Specifies that the method or property will ensure that the listed field and property
            members have not-null values when returning with the specified return value condition.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.MemberNotNullWhenAttribute.#ctor(System.Boolean,System.String)">
            <summary>
            Initializes the attribute with the specified return value condition and a field or property member.
            </summary>
            <param name="returnValue">The return value condition. If the method returns this value, the associated parameter will not be null.</param>
            <param name="member">The field or property member that is promised to be not-null.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.MemberNotNullWhenAttribute.#ctor(System.Boolean,System.String[])">
            <summary>
            Initializes the attribute with the specified return value condition and list of field and property members.
            </summary>
            <param name="returnValue">The return value condition. If the method returns this value, the associated parameter will not be null.</param>
            <param name="members">The list of field and property members that are promised to be not-null.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.MemberNotNullWhenAttribute.ReturnValue">
            <summary>
            Gets the return value condition.
            </summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.MemberNotNullWhenAttribute.Members">
            <summary>
            Gets field or property member names.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.NotNullAttribute">
            <summary>
            Specifies that an output will not be null even if the corresponding type allows it.
            Specifies that an input argument was not null when the call returns.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.NotNullIfNotNullAttribute">
            <summary>
            Specifies that the output will be non-null if the named parameter is non-null.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.NotNullIfNotNullAttribute.#ctor(System.String)">
            <summary>
            Initializes the attribute with the associated parameter name.
            </summary>
            <param name="parameterName">The associated parameter name. The output will be non-null if the argument to the parameter specified is non-null.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.NotNullIfNotNullAttribute.ParameterName">
            <summary>
            Gets the associated parameter name.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.NotNullWhenAttribute">
            <summary>
            Specifies that when a method returns <see cref="P:System.Diagnostics.CodeAnalysis.NotNullWhenAttribute.ReturnValue"/>, the parameter will not be null even if the corresponding type allows it.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.NotNullWhenAttribute.#ctor(System.Boolean)">
            <summary>
            Initializes the attribute with the specified return value condition.
            </summary>
            <param name="returnValue">The return value condition. If the method returns this value, the associated parameter will not be null.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.NotNullWhenAttribute.ReturnValue">
            <summary>Gets the return value condition.</summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.SetsRequiredMembersAttribute">
            <summary>
            Specifies that this constructor sets all required members for the current type,
            and callers do not need to set any required members themselves.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute">
            <summary>
            Specifies the syntax used in a string.
            </summary>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.#ctor(System.String)">
            <summary>
            Initializes the <see cref="T:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute"/> with the identifier of the syntax used.
            </summary>
            <param name="syntax">The syntax identifier.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.#ctor(System.String,System.Object[])">
            <summary>Initializes the <see cref="T:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute"/> with the identifier of the syntax used.</summary>
            <param name="syntax">The syntax identifier.</param>
            <param name="arguments">Optional arguments associated with the specific syntax employed.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.Syntax">
            <summary>Gets the identifier of the syntax used.</summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.Arguments">
            <summary>Optional arguments associated with the specific syntax employed.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.CompositeFormat">
            <summary>The syntax identifier for strings containing composite formats for string formatting.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.DateOnlyFormat">
            <summary>The syntax identifier for strings containing date format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.DateTimeFormat">
            <summary>The syntax identifier for strings containing date and time format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.EnumFormat">
            <summary>The syntax identifier for strings containing <see cref="T:System.Enum"/> format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.GuidFormat">
            <summary>The syntax identifier for strings containing <see cref="T:System.Guid"/> format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.Json">
            <summary>The syntax identifier for strings containing JavaScript Object Notation (JSON).</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.NumericFormat">
            <summary>The syntax identifier for strings containing numeric format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.Regex">
            <summary>The syntax identifier for strings containing regular expressions.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.TimeOnlyFormat">
            <summary>The syntax identifier for strings containing time format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.TimeSpanFormat">
            <summary>The syntax identifier for strings containing <see cref="T:System.TimeSpan"/> format specifiers.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.Uri">
            <summary>The syntax identifier for strings containing URIs.</summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.StringSyntaxAttribute.Xml">
            <summary>The syntax identifier for strings containing XML.</summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.UnscopedRefAttribute">
            <summary>
            Used to indicate a byref escapes and is not scoped.
            </summary>
            <remarks>
            <para>
            There are several cases where the C# compiler treats a <see langword="ref"/> as implicitly
            <see langword="scoped"/> - where the compiler does not allow the <see langword="ref"/> to escape the method.
            </para>
            <para>
            For example:
            <list type="number">
                <item><see langword="this"/> for <see langword="struct"/> instance methods.</item>
                <item><see langword="ref"/> parameters that refer to <see langword="ref"/> <see langword="struct"/> types.</item>
                <item><see langword="out"/> parameters.</item>
            </list>
            </para>
            <para>
            This attribute is used in those instances where the <see langword="ref"/> should be allowed to escape.
            </para>
            <para>
            Applying this attribute, in any form, has impact on consumers of the applicable API. It is necessary for
            API authors to understand the lifetime implications of applying this attribute and how it may impact their users.
            </para>
            </remarks>
        </member>
        <member name="T:System.Index">
            <summary>Represent a type can be used to index a collection either from the start or the end.</summary>
            <remarks>
            Index is used by the C# compiler to support the new index syntax
            <code>
            int[] someArray = new int[5] { 1, 2, 3, 4, 5 } ;
            int lastElement = someArray[^1]; // lastElement = 5
            </code>
            </remarks>
        </member>
        <member name="M:System.Index.#ctor(System.Int32,System.Boolean)">
            <summary>Construct an Index using a value and indicating if the index is from the start or from the end.</summary>
            <param name="value">The index value. it has to be zero or positive number.</param>
            <param name="fromEnd">Indicating if the index is from the start or from the end.</param>
            <remarks>
            If the Index constructed from the end, index value 1 means pointing at the last element and index value 0 means pointing at beyond last element.
            </remarks>
        </member>
        <member name="P:System.Index.Start">
            <summary>Create an Index pointing at first element.</summary>
        </member>
        <member name="P:System.Index.End">
            <summary>Create an Index pointing at beyond last element.</summary>
        </member>
        <member name="M:System.Index.FromStart(System.Int32)">
            <summary>Create an Index from the start at the position indicated by the value.</summary>
            <param name="value">The index value from the start.</param>
        </member>
        <member name="M:System.Index.FromEnd(System.Int32)">
            <summary>Create an Index from the end at the position indicated by the value.</summary>
            <param name="value">The index value from the end.</param>
        </member>
        <member name="P:System.Index.Value">
            <summary>Returns the index value.</summary>
        </member>
        <member name="P:System.Index.IsFromEnd">
            <summary>Indicates whether the index is from the start or the end.</summary>
        </member>
        <member name="M:System.Index.GetOffset(System.Int32)">
            <summary>Calculate the offset from the start using the giving collection length.</summary>
            <param name="length">The length of the collection that the Index will be used with. length has to be a positive value</param>
            <remarks>
            For performance reason, we don't validate the input length parameter and the returned offset value against negative values.
            we don't validate either the returned offset is greater than the input length.
            It is expected Index will be used with collections which always have non negative length/count. If the returned offset is negative and
            then used to index a collection will get out of range exception which will be same affect as the validation.
            </remarks>
        </member>
        <member name="M:System.Index.Equals(System.Object)">
            <summary>Indicates whether the current Index object is equal to another object of the same type.</summary>
            <param name="value">An object to compare with this object</param>
        </member>
        <member name="M:System.Index.Equals(System.Index)">
            <summary>Indicates whether the current Index object is equal to another Index object.</summary>
            <param name="other">An object to compare with this object</param>
        </member>
        <member name="M:System.Index.GetHashCode">
            <summary>Returns the hash code for this instance.</summary>
        </member>
        <member name="M:System.Index.op_Implicit(System.Int32)~System.Index">
            <summary>Converts integer number to an Index.</summary>
        </member>
        <member name="M:System.Index.ToString">
            <summary>Converts the value of the current Index object to its equivalent string representation.</summary>
        </member>
        <member name="T:System.Range">
            <summary>Represent a range has start and end indexes.</summary>
            <remarks>
            Range is used by the C# compiler to support the range syntax.
            <code>
            int[] someArray = new int[5] { 1, 2, 3, 4, 5 };
            int[] subArray1 = someArray[0..2]; // { 1, 2 }
            int[] subArray2 = someArray[1..^0]; // { 2, 3, 4, 5 }
            </code>
            </remarks>
        </member>
        <member name="P:System.Range.Start">
            <summary>Represent the inclusive start index of the Range.</summary>
        </member>
        <member name="P:System.Range.End">
            <summary>Represent the exclusive end index of the Range.</summary>
        </member>
        <member name="M:System.Range.#ctor(System.Index,System.Index)">
            <summary>Construct a Range object using the start and end indexes.</summary>
            <param name="start">Represent the inclusive start index of the range.</param>
            <param name="end">Represent the exclusive end index of the range.</param>
        </member>
        <member name="M:System.Range.Equals(System.Object)">
            <summary>Indicates whether the current Range object is equal to another object of the same type.</summary>
            <param name="value">An object to compare with this object</param>
        </member>
        <member name="M:System.Range.Equals(System.Range)">
            <summary>Indicates whether the current Range object is equal to another Range object.</summary>
            <param name="other">An object to compare with this object</param>
        </member>
        <member name="M:System.Range.GetHashCode">
            <summary>Returns the hash code for this instance.</summary>
        </member>
        <member name="M:System.Range.ToString">
            <summary>Converts the value of the current Range object to its equivalent string representation.</summary>
        </member>
        <member name="M:System.Range.StartAt(System.Index)">
            <summary>Create a Range object starting from start index to the end of the collection.</summary>
        </member>
        <member name="M:System.Range.EndAt(System.Index)">
            <summary>Create a Range object starting from first element in the collection to the end Index.</summary>
        </member>
        <member name="P:System.Range.All">
            <summary>Create a Range object starting from first element to the end.</summary>
        </member>
        <member name="M:System.Range.GetOffsetAndLength(System.Int32)">
            <summary>Calculate the start offset and length of range object using a collection length.</summary>
            <param name="length">The length of the collection that the range will be used with. length has to be a positive value.</param>
            <remarks>
            For performance reason, we don't validate the input length parameter against negative values.
            It is expected Range will be used with collections which always have non negative length/count.
            We validate the range is inside the length scope though.
            </remarks>
        </member>
        <member name="T:System.Runtime.CompilerServices.CallerArgumentExpressionAttribute">
            <summary>
            An attribute that allows parameters to receive the expression of other parameters.
            </summary>
        </member>
        <member name="M:System.Runtime.CompilerServices.CallerArgumentExpressionAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Runtime.CompilerServices.CallerArgumentExpressionAttribute"/> class.
            </summary>
            <param name="parameterName">The condition parameter value.</param>
        </member>
        <member name="P:System.Runtime.CompilerServices.CallerArgumentExpressionAttribute.ParameterName">
            <summary>
            Gets the parameter name the expression is retrieved from.
            </summary>
        </member>
        <member name="M:System.Runtime.CompilerServices.CollectionBuilderAttribute.#ctor(System.Type,System.String)">
            <summary>
            Initialize the attribute to refer to the <paramref name="methodName"/> method on the <paramref name="builderType"/> type.
            </summary>
            <param name="builderType">The type of the builder to use to construct the collection.</param>
            <param name="methodName">The name of the method on the builder to use to construct the collection.</param>
            <remarks>
            <paramref name="methodName"/> must refer to a static method that accepts a single parameter of
            type <see cref="T:System.ReadOnlySpan`1"/> and returns an instance of the collection being built containing
            a copy of the data from that span.  In future releases of .NET, additional patterns may be supported.
            </remarks>
        </member>
        <member name="P:System.Runtime.CompilerServices.CollectionBuilderAttribute.BuilderType">
            <summary>
            Gets the type of the builder to use to construct the collection.
            </summary>
        </member>
        <member name="P:System.Runtime.CompilerServices.CollectionBuilderAttribute.MethodName">
            <summary>
            Gets the name of the method on the builder to use to construct the collection.
            </summary>
            <remarks>
            This should match the metadata name of the target method.
            For example, this might be ".ctor" if targeting the type's constructor.
            </remarks>
        </member>
        <member name="T:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute">
            <summary>
            Indicates that compiler support for a particular feature is required for the location where this attribute is applied.
            </summary>
        </member>
        <member name="M:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.#ctor(System.String)">
            <summary>
            Creates a new instance of the <see cref="T:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute"/> type.
            </summary>
            <param name="featureName">The name of the feature to indicate.</param>
        </member>
        <member name="P:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.FeatureName">
            <summary>
            The name of the compiler feature.
            </summary>
        </member>
        <member name="P:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.IsOptional">
            <summary>
            If true, the compiler can choose to allow access to the location where this attribute is applied if it does not understand <see cref="P:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.FeatureName"/>.
            </summary>
        </member>
        <member name="F:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.RefStructs">
            <summary>
            The <see cref="P:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.FeatureName"/> used for the ref structs C# feature.
            </summary>
        </member>
        <member name="F:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.RequiredMembers">
            <summary>
            The <see cref="P:System.Runtime.CompilerServices.CompilerFeatureRequiredAttribute.FeatureName"/> used for the required members C# feature.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.InterpolatedStringHandlerArgumentAttribute">
            <summary>
            Indicates which arguments to a method involving an interpolated string handler should be passed to that handler.
            </summary>
        </member>
        <member name="M:System.Runtime.CompilerServices.InterpolatedStringHandlerArgumentAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Runtime.CompilerServices.InterpolatedStringHandlerArgumentAttribute"/> class.
            </summary>
            <param name="argument">The name of the argument that should be passed to the handler.</param>
            <remarks><see langword="null"/> may be used as the name of the receiver in an instance method.</remarks>
        </member>
        <member name="M:System.Runtime.CompilerServices.InterpolatedStringHandlerArgumentAttribute.#ctor(System.String[])">
            <summary>
            Initializes a new instance of the <see cref="T:System.Runtime.CompilerServices.InterpolatedStringHandlerArgumentAttribute"/> class.
            </summary>
            <param name="arguments">The names of the arguments that should be passed to the handler.</param>
            <remarks><see langword="null"/> may be used as the name of the receiver in an instance method.</remarks>
        </member>
        <member name="P:System.Runtime.CompilerServices.InterpolatedStringHandlerArgumentAttribute.Arguments">
            <summary>
            Gets the names of the arguments that should be passed to the handler.
            </summary>
            <remarks><see langword="null"/> may be used as the name of the receiver in an instance method.</remarks>
        </member>
        <member name="T:System.Runtime.CompilerServices.InterpolatedStringHandlerAttribute">
            <summary>
            Indicates the attributed type is to be used as an interpolated string handler.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.IsExternalInit">
            <summary>
            Reserved to be used by the compiler for tracking metadata.
            This class should not be used by developers in source code.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.ModuleInitializerAttribute">
             <summary>
             Used to indicate to the compiler that a method should be called
             in its containing module's initializer.
             </summary>
             <remarks>
             When one or more valid methods
             with this attribute are found in a compilation, the compiler will
             emit a module initializer which calls each of the attributed methods.
            
             Certain requirements are imposed on any method targeted with this attribute:
             - The method must be `static`.
             - The method must be an ordinary member method, as opposed to a property accessor, constructor, local function, etc.
             - The method must be parameterless.
             - The method must return `void`.
             - The method must not be generic or be contained in a generic type.
             - The method's effective accessibility must be `internal` or `public`.
            
             The specification for module initializers in the .NET runtime can be found here:
             https://github.com/dotnet/runtime/blob/main/docs/design/specs/Ecma-335-Augments.md#module-initializer
             </remarks>
        </member>
        <member name="T:System.Runtime.CompilerServices.OverloadResolutionPriorityAttribute">
            <summary>
            Specifies the priority of a member in overload resolution. When unspecified, the default priority is 0.
            </summary>
        </member>
        <member name="M:System.Runtime.CompilerServices.OverloadResolutionPriorityAttribute.#ctor(System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Runtime.CompilerServices.OverloadResolutionPriorityAttribute"/> class.
            </summary>
            <param name="priority">The priority of the attributed member. Higher numbers are prioritized, lower numbers are deprioritized. 0 is the default if no attribute is present.</param>
        </member>
        <member name="P:System.Runtime.CompilerServices.OverloadResolutionPriorityAttribute.Priority">
            <summary>
            The priority of the member.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.ParamCollectionAttribute">
            <summary>
            Indicates that a method will allow a variable number of arguments in its invocation.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.RequiredMemberAttribute">
            <summary>
            Specifies that a type has required members or that a member is required.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.RequiresLocationAttribute">
            <summary>
            Reserved for use by a compiler for tracking metadata.
            This attribute should not be used by developers in source code.
            </summary>
        </member>
        <member name="T:System.Runtime.CompilerServices.SkipLocalsInitAttribute">
            <summary>
            Used to indicate to the compiler that the <c>.locals init</c> flag should not be set in method headers.
            </summary>
        </member>
        <member name="M:System.Runtime.Versioning.RequiresPreviewFeaturesAttribute.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:System.Runtime.Versioning.RequiresPreviewFeaturesAttribute"/> class.
            </summary>
        </member>
        <member name="M:System.Runtime.Versioning.RequiresPreviewFeaturesAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Runtime.Versioning.RequiresPreviewFeaturesAttribute"/> class with the specified message.
            </summary>
            <param name="message">An optional message associated with this attribute instance.</param>
        </member>
        <member name="P:System.Runtime.Versioning.RequiresPreviewFeaturesAttribute.Message">
            <summary>
            Returns the optional message associated with this attribute instance.
            </summary>
        </member>
        <member name="P:System.Runtime.Versioning.RequiresPreviewFeaturesAttribute.Url">
            <summary>
            Returns the optional URL associated with this attribute instance.
            </summary>
        </member>
    </members>
</doc>
